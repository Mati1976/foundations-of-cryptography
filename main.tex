\documentclass[a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{lastpage}
\usepackage{pgf}
\usepackage{wrapfig}
\usepackage{fancyvrb}
\usepackage{fancyhdr}
\usepackage{url}
\usepackage{array}
\usepackage{tikz}
\usetikzlibrary{patterns}
% \usetikzlibrary{crypto.symbols}
\pagestyle{fancy}
\setlength{\parindent}{0pt}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{shapes}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\renewcommand\algorithmicdo{}
\renewcommand\algorithmicthen{}
\usepackage{amssymb}
\newcommand{\inv}{^{\raisebox{.2ex}{$\scriptscriptstyle-1$}}}
\newcommand{\ts}{\textsuperscript}
\usepackage{listings}
\usepackage[full]{complexity}

% Remove hyphenation
\usepackage[british]{babel}
\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000
\setlength{\parskip}{0.5cm plus4mm minus3mm}

% Create header and footer
\headheight 27pt
\renewcommand{\headrulewidth}{0.4pt}
\fancyhead[L]{DD2448}
\fancyhead[R]{Phillip Gajland}
\fancyfoot[C]{\thepage\ (\pageref{LastPage})}

% Create title page
\title{Foundations of Cryptography}
\subtitle{Summary of the course DD2448 taught at\\KTH Royal Institute of Technology by Douglas Wikström}
\author{Phillip Gajland}
\date{Spring 2019}

\begin{document}
\thispagestyle{empty}
\maketitle

\section*{Lecture 1 - Introduction \& Symmetric Cryptosystems}

\subsection*{General}

\begin{itemize}
\item Alice encrypts a message $m$ using key $k$ and encryption algorithm $E$ such that $c = E_k(m)$. Bob decrypts the ciphertext $c$ using the same key $k$ and decryption algorithm  $E\inv$ such that $m = E_k\inv(c)$.
\item Mathematically, a cryptosystem can be defined as a tuple $({\mathcal Gen},{\mathcal {P}}, E, E\inv)$ where:
\begin{itemize}
\item [$\circ$] ${\mathcal Gen}$ is a key generation algorithm for keys in the key space ${\mathcal {K}}$.
\item [$\circ$] ${\mathcal {P}}$ is the set of plaintexts.
\item [$\circ$] $E$ is a deterministic encryption algorithm.
\item [$\circ$] $E\inv$ is a deterministic decryption algorithm.
\end{itemize}
such that $E_k\inv(E_k(m)) = m$ for every message $m \in {\mathcal {P}}$ and $k \in {\mathcal {K}}$
\item The set ${\mathcal {C}} = E_k(m) \mid m \in {\mathcal {P}} \land k \in {\mathcal {K}}$ is called the set of ciphertexts.

(Pronounced: \textit{$E_k(m)$ such that $m$ is in ${\mathcal {P}}$ and $k$ is in ${\mathcal {K}}$.} I.e. all combinations of keys $k$ and messages $m$.
\end{itemize}

\subsection*{Caesar Cipher}

\begin{itemize}
\item In an alphabet containing 26 letters, the key $k$ is such that $k \in \mathbb{Z}_{26}$.
\item The plaintext $m = (m_1, ..., m_n) \in \mathbb{Z}_{26}^{n}$ gives ciphertext $c = (c_1, ..., c_n)$.
\item Encryption is given by $c_i = m_i + k \mod 26$.
\item Decryption is given by $m_i = c_i - k \mod 26$.
\item The key space ${\mathcal {K}}$ is too small, making it susceptible to brute force attacks.
\item A frequency analysis can be done by maximising the inner product $T(E\inv(C)) \cdot F$ where $T(s) \cdot F$ denotes the frequency table of string $s$ and the English language respectively.
\end{itemize}

\section*{Lecture 2 - More Symmetric Cryptosystems}

\subsection*{Affine Cipher}

\begin{itemize}
\item The key $k$ is given by a random pair $(a, b)$, where $a \in \mathbb{Z}_{26}$ is relatively prime to 26, and $b \in \mathbb{Z}_{26}$.
\item The plaintext $m = (m_1, ..., m_n) \in \mathbb{Z}_{26}^{n}$ gives ciphertext $c = (c_1, ..., c_n)$.
\item Encryption is given by $c_i = am_i + b \mod 26$.
\item Decryption is given by $m_i = (c_i - b)a^{-1} \mod 26$.
\item \textsl{Relative primality of $a$ and 26 implies that $(a^{-1} \mod 26)$ exists.}
\end{itemize}

\subsection*{Substitution Cipher}

\begin{itemize}
\item Both the Caesar cipher and affine cipher are examples of substitution ciphers.
\item The key is a random permutation $\sigma \in {\mathcal {S}}$ of the symbols in the alphabet, for some subset ${\mathcal {S}}$ of all permutations.
\item The plaintext $m = (m_1, ..., m_n) \in \mathbb{Z}_{26}^{n}$ gives ciphertext $c = (c_1, ..., c_n)$.
\item Encryption is given by $c_i = \sigma(m_i)$.
\item Decryption is given by $m_i = \sigma^{-1}(c_i)$.
\end{itemize}

\subsubsection*{Generic Attacks on Substitution Ciphers}

\begin{itemize}
\item A \textbf{digram} is an ordered pair of symbols.
\item A \textbf{trigram} is an ordered triple of symbols.
\item It is useful to compute frequency tables for the most frequent digrams and trigrams, and not only the frequencies for individual symbols. 

\begin{enumerate}
\item Compute symbol / digram / trigram frequency tables for the candidate language and the ciphertext.
\item Try to match symbols / digrams / trigrams with similar frequencies. 
\item Try to recognise words to confirm guesses (using dictionary or Google).
\item Repeat until the plaintext can be guessed.
\end{enumerate}
\item This is hard when several symbols have similar frequencies - a large amount of cipher text is needed.
\end{itemize}

\subsection*{Vigenère Cipher}

\begin{itemize}
\item The key is given by $k = (k_0, ..., k_{l - 1})$, where $k_i \in \mathbb{Z}_{26}$ is random.
\item The plaintext $m = (m_1, ..., m_n) \in \mathbb{Z}_{26}^{n}$ gives ciphertext $c = (c_1, ..., c_n)$.
\item Encryption is given by $c_i = m_i + k_{i \mod l} \mod 26$.
\item Decryption is given by $m_i = c_i - k_{i \mod l} \mod 26$.
\item \textsl{This gives a more uniform frequency table.}
\end{itemize}

\subsubsection*{Attack on Vigenère Cipher}

\begin{itemize}
\item Each probability distribution $p_1, ..., p_n$ on $n$ symbols may be viewed as a point $p = (p1, ..., p_n)$ on a $n - 1$ dimensional hyperplane in $\mathbb{R}^n$ orthogonal to the vector $\overline{1} = (1, ..., 1)$.
\item Such a point $p = (p_1, ..., p_n)$ is at a distance $\sqrt{F(p)}$ from the origin, where $F(p) = \sum^{n}_{i = 1} p^2_i$.
\item It is clear that $p$ is closest to the origin, when $p$ is the uniform distribution, i.e., when $F(p)$ is minimised.
\item $F(p)$ is invariant under permutation of the underlying symbols. Use tools to check if a set of symbols is the result of some substitution cipher. 
\begin{enumerate}
\item For $l = 1, 2, 3, ...$ we form\\[0.25cm] 
$
\begin{pmatrix}
C_{0} \\
C_{1} \\
\vdots \\
C_{l-1} 
\end{pmatrix} 
=
\begin{pmatrix}
c_{0} & c_{l} & c_{2l} & \cdots \\
c_{1} & c_{l+1} & c_{2l+1} & \cdots \\
\vdots  & \vdots  & \vdots & \ddots \\
c_{l-1} & c_{2l-1} & c_{3l-1} & \cdots 
\end{pmatrix}$\\[0.25cm]
and compute $f_l = \frac{1}{l} \sum^{l-1}_{i=0}F(C_i)$.
\item The local maximum with smallest $l$ is probably the right length.
\item Then attack each $C_i$ separately to recover $k_i$, using the attack against the Caesar cipher.
\end{enumerate}
\end{itemize}

\subsection*{Hill Cipher}

\begin{itemize}
\item The key is given by $k = A$, where $a$ is an invertible $l \times l$-matrix over $\mathbb{Z}_{26}$.
\item The plaintext $m = (m_1, ..., m_n) \in \mathbb{Z}_{26}^{n}$ gives ciphertext $c = (c_1, ..., c_n)$.
\item Encryption is given by $(c_{i+0}, ..., c_{i+l-1}) = (m_{i+0}, ..., m_{i+l-1})A$.
\item Decryption is given by $(c_{i+0}, ..., c_{i+l-1}) = (m_{i+0}, ..., m_{i+l-1})A^{-1}$.\\[0.25cm]
for $i = 1, l + 1, 2l + 1, ...$
\item The Hill cipher is easy to break using a \textbf{known plaintext attack}.
\end{itemize}

\subsection*{Permutation Cipher}

\begin{itemize}
\item The permutation cipher is a special case of the Hill cipher.
\item The key is given by a random permutation $\pi \in \mathcal{S}$ for some subset $\mathcal{S}$ of the set of permutation of $\{0, 1, 2, ..., l -1\}$.
\item The plaintext $m = (m_1, ..., m_n) \in \mathbb{Z}_{26}^{n}$ gives ciphertext $c = (c_1, ..., c_n)$.
\item Encryption is given by $c_i = m_{\lfloor i / l \rfloor + \pi (i \mod l)}$.
\item Decryption is given by $m_i = c_{\lfloor i / l \rfloor + \pi^{-1} (i \mod l)}$.
\end{itemize}

\subsection*{Summary of Simple Ciphers}

\begin{itemize}
\item Caesar cipher and affine cipher: $m_i \mapsto am_i + b$.
\item Substitution cipher (generalise Caesar / affine): $m_i \mapsto \sigma(m_i)$.
\item Vigenère cipher (more uniform frequency table): $m_i \mapsto m_i + k_{i \mod l}$.
\item Hill cipher (invertible linear map): $(m_1, ..., m_l) \mapsto (m_1, ..., ..., m_l)A$.
\item Transposition cipher (permutation): $(m_1, ..., m_l) \mapsto (m_{\pi(1)}, ..., m_{\pi(l)})$\\
equivalent to: $(m_1, ..., m_l) \mapsto (m_1, ..., m_l)M_\pi$.
\end{itemize}

\subsection*{Good Block Ciphers}

\begin{itemize}
\item Simple ciphers are bad, but what makes a good block cipher?
\item For every key a block-cipher with plaintext / ciphertext space $\{0, 1\}^n$ gives a permutation of $\{0, 1\}^n$.
\begin{itemize}
\item [$\circ$] What would be a good cipher?
\end{itemize}
\item A good cipher is one where each key gives a \textbf{randomly chosen permutation} of $\{0, 1\}^n$.
\begin{itemize}
\item [$\circ$] Why is this not possible?
\end{itemize}
\item The representation of a single typical function $\{0, 1\}^n \rightarrow \{0, 1\}^n$ requires roughly $n2^n$ bits $(147 \times 10^{6 \cdot 3}$ for $n = 64)$.
\begin{itemize}
\item [$\circ$] What should we look for instead?
\end{itemize}
\item \textbf{Idea:} Compose smaller weak ciphers into a large one. Mix the components thoroughly. Claude Shannon (1948) introduces two terms:
\begin{itemize}
\item [$\circ$] \textbf{Diffusion:} "In the method of diffusion the statistical structure of $M$ which leads to its redundancy is dissipated into long range statistics..."
\item [$\circ$] \textbf{Confusion:} "The method of confusion is to make the relation between the simple statistics of $E$ and the simple description of $K$ a very complex and involved one."
\end{itemize}
\end{itemize}

\section*{Lecture 3 - Substitution-Permutation Networks \& AES}

\subsection*{Substitution-Permutation Networks}

\begin{itemize}
\item Block-size: We use a block-size of $n = l \times m$ bits.
\item Key Schedule: Round $r$ uses its own round key $K_r$ derived from the key $K$ using a key schedule.
\item Each Round the following is invoked:
\begin{enumerate}
\item Round Key: xor with the round key.
\item Substitution: $l$ substitution boxes each acting on one $m$-bit word ($m$-bit S-Boxes).
\item Permutation: A permutation $\pi_i$ acting on $\{1, ..., n\}$ to reorder the $n$ bits.
\end{enumerate}
\end{itemize}

\subsection*{A Simple Block Cipher}

\begin{itemize}
\item $|P| = |C| = 16$
\item 4 rounds
\item $|K| = 32$
\item $r$\ts{th} round key $K_r$ consists of the 4$r$\ts{th} to the $(4r + 16)$\ts{th} bits of key $K$.
\item 4-bit S-Boxes
\item S-Boxes the same $(S \neq S\inv)$
\item $Y = S(X)$
\item Can be described using 4 boolean functions.
\end{itemize}

\subsection*{Advanced Encryption Standard (AES)}

\begin{itemize}
\item Chosen in worldwide public competition 1997-2000. Probably no backdoors. Increased confidence!
\item Winning proposal named "Rijndael", by Rijmen and Daemen.
\item Family of 128-bit ciphers: \{Key bits, Rounds\} - \{128, 10\}, \{192, 12\}, \{256, 14\}. 
\item The first key-recovery attacks on full AES found by Bogdanov, Khovratovich, and Rechberger was published in 2011 and is faster than brute force by a factor of about 4. 
\item The algebraics of AES have made some people \textit{uneasy}, but they have been uneasy for years now...
\begin{itemize}
\item [$\circ$] AddRoundKey: xor with round key.
\item [$\circ$] SubBytes: Substitution of bytes.
\item [$\circ$] ShiftRows: Permutation of bytes.
\item [$\circ$] MixXolumns: Linear map.
\end{itemize}
\end{itemize}

\begin{itemize}
\item The 128 bit state is interpreted as a $4 \times 4$ matrix of bytes.
\begin{center}
\input{matrix.tex}
\end{center}
\item Something like a mix between substitution, permutation, affine version of Hill cipher. In each round!
\item SubBytes is a field inversion in $\mathbb{F}_{2^8}$ plus affine map in $\mathbb{F}_{2}^8$.
\item ShiftRows is ac cyclic shift of bytes with offsets: 0, 1, 2, and 3.
\item MixColumns is an invertible linear map over $\mathbb{F}_{2^8}$ (with irreducible polynomial $x^8 + x^4 +x^3 + x + 1)$ with good diffusion. 
\item Decryption uses the following transforms:
\begin{itemize}
\item [$\circ$] AddRoundKey
\item [$\circ$] InvSubBytes
\item [$\circ$] InvShiftRows
\item [$\circ$] InvMixColumns
\end{itemize}
\end{itemize}

\subsection*{Feistel Networks}

\begin{itemize}
\item Identical rounds are iterated, but with different round keys.
\item The input to the $i$\ts{th} round is divided in a left and right part, denoted $L^{i-1}$ and $R^{i-1}$.
\item $f$ is a function for which it is somewhat hard to find pre-images, but $f$ is \textbf{not invertible}!
\item One round is defined by:\\ 
$L^i = R^{i-1}$\\$R^i = L^{i-1} \oplus f(R^{i-1}, K^i)$\\
where $K^i$ is the $i$\ts{th} round key.
\item The inverse Feistel round is given by:\\ 
$L^{i-1} = R^i \oplus f(L^i, K^i)$\\$R^{i-1} = L^i$\\
I.e. reverse direction and swap left and right.
\end{itemize}

\subsection*{Data Encryption Standard (DES)}
\begin{itemize}
\item Developed at IBM in 1975, or perhaps at NSA; not publicly known.
\item 16-round Feistel network.
\item Key schedule derives permuted bits for each round key from a 56-bit key. Supposedly not 64-bit due to parity bits.
\item DES's $f$-Function is given by: $f(R^{i-1}, K^i)$
\end{itemize}

\subsection*{Security of DES}
\begin{itemize}
\item Brute Force: Try all $2^56$ keys. Done in practice with special chip by Electronic Frontier Foundation, 1998. Possibly much earlier by NSA and others.
\item Differential Cryptanalysis: $2^{47}$ chosen plaintexts, Biham and Shamir, 1991. Known earlier by IBM and NSA. DES is surprisingly resistant!
\item Linear Cryptanalysis: $2^{43}$ known plaintexts, Matsui, 1993. Probably \textbf{not} known by IBM and NSA!
\item Since the key space for DES is too small, one way to increase it is to use DES twice, so called "double DES".
$2DES_{k_1,k_2}(x) = DES_{k_2}(DES_{k_1}(x))$.
\item However, this is \textbf{not} more secure than normal DES! 
\item Meet-in-the-middle attack:
\begin{itemize}
\item [$\circ$] Get hold of a plaintext-ciphertext pair $(m, c)$.
\item [$\circ$] Compute $X = \{x \mid k_1 \in \mathcal{K}_{DES} \land x = E_{k_1}(m) \}$.
\item [$\circ$] For $k_2 \in \mathcal{K}_{DES}$ check if $E_{k_2}^{-1}(c) = E_{k_1}(m)$ for some $k_1$ using the table $X$. If so, then $(k_1, k_2)$ is a good candidate.
\item [$\circ$] Repeat with $(m', c')$, starting from the set of candidate keys to identify the correct key.
\end{itemize}
\item Tripple DES: $3DES_{k_1,k_2,k_3}(x) = DES_{k_3}(DES_{k_2}(DES_{k_1}(x)))$.
\item Seemingly 112 bit "effective" key size.
\item 3 times as slow as DES. DES is slow in software, and this is even worse. One of the motivation for AES. 
\item Triple DES is sill considered to be secure.
\end{itemize}

\subsection*{Modes of Operation}
\begin{itemize}
\item 5 modes of operation:
\begin{itemize}
\item [$\circ$] Electronic codebook mode (ECB mode).
\item [$\circ$] Cipher feedback mode (CFB mode).
\item [$\circ$] Cipher block chaining mode (CBC mode).
\item [$\circ$] Output feedback mode (OFB mode).
\item [$\circ$] Counter mode (CTR mode).
\end{itemize}
\item \textbf{Electronic codebook mode} - encrypt each block independently: $c_i = E_k(m_i)$.
\item Identical plaintext blocks give identical ciphertext blocks.
\item \textbf{Cipher feedback mode} - xor plaintext block with previous ciphertext block \textbf{after} encryption:\\$c_0 =$ initialisation vector\\$c_i = m_i \oplus E_k(c_{i-1})$.
\item Sequential encryption and parallel decryption.
\item Self-synchronising and unidirectional.
\item \textbf{Cipher block chaining mode} - xor plaintext block with previous ciphertext block \textbf{after} encryption:\\$c_0 =$ initialisation vector\\$c_i = E_k(c_{i-1} \oplus m_i)$.
\item Sequential encryption and parallel decryption.
\item Self-synchronising.
\item \textbf{Output feedback mode} - generate stream, xor plaintexts with stream (emulate "one-time pad"):\\$s_0 =$ initialisation vector\\$s_i = E_k(s_{i-1})$\\$c_i = s_i \oplus m_i$.
\item Sequential. 
\item Synchronous.
\item Allows batch processing.
\item Malleable!
\item \textbf{Counter mode} - generate stream, xor plaintexts with stream (emulate "one-time pad"):\\$s_0 =$ initialisation vector\\$s_i = E_k(s_{0} || i)$\\$c_i = s_i \oplus m_i$.
\item Parallel.
\item Synchronous.
\item allows batch processing.
\item Malleable!
\end{itemize}

\section*{Lecture 4 - Cryptanalysis of the Simple Permutation Network}

\begin{itemize}
\item Find an expression of the following form with a high probability of occurrence. 
$$P_{i_1} \oplus \cdots \oplus P_{i_p} \oplus C_{j_1} \oplus \cdots \oplus C_{j_c} = K_{l_1, s_1} \oplus \cdots \oplus K_{l_k, s_k}$$
\item Each random plaintext / ciphertext pair gives an estimate of $$K_{l_1, s_1} \oplus \cdots \oplus K_{l_k, s_k}$$
\item Collect many pairs and make a better estimate based on the majority vote.
\item How do we come up with the desired expression?
\item How do we compute the required number of samples?
\end{itemize}
\subsection*{Bias}
\begin{itemize}
\item The bias $\epsilon(X)$ of a binary random variable $X$ is defined by $$\epsilon(X) = Pr [X = 0] - \frac{1}{2}$$
$\approx 1 / \epsilon^2(X)$ samples are required to estimate $X$.
\end{itemize}

\subsection*{Linear Approximation of S-Box}
\begin{itemize}
\item Let $X$ and $Y$ be the input and output of an $S$-box, i.e. {\boldmath$Y = S(X)$}.
\item We consider the bias of linear combinations of the form $$a \cdot X \oplus b \cdot Y = \Bigg(\bigoplus_{i}a_iX_i\Bigg) \oplus \Bigg(\bigoplus_{i}b_iY_i\Bigg)$$
\item Example: $X_2 \oplus X_3 = Y_1 \oplus Y_3 \oplus Y_4$. The expression holds in 12 out of the 16 cases. Hence, it has a bias of (12-8)/16 = 4/16 = 1/4.
\item Let $N_L(a, b)$ be the number of zero-outcomes of a $a \cdot X \oplus b \cdot Y$.
\item The bias is then $$\epsilon(a \cdot X \oplus b \cdot Y = \frac{N_L(a,b) - 8}{16},$$ since there are four bits in $X$, and $Y$ is determined by $X$.
\item This gives a linear approximation for one round.
\item How do we come up with a linear approximation for more rounds?
\end{itemize}

\subsection*{Piling-Up Lemma}

\begin{itemize}
\item Let $X_1, ..., X_t$ be independent binary random variables and let $\epsilon_i = \epsilon(X_i)$. Then $$\epsilon \Bigg(\bigoplus_{i}X_i\Bigg) = 2^{t-1} \prod_{i} \epsilon_i .$$ 
\item Proof: Case $t = 2$:
\begin{align*}
Pr[X_1 \oplus X_2 = 0] &= Pr[X_1 = 0 \land X_1 = 0) \lor (X_1 = 1 \land X_1 = 1)]\\
&= (\frac{1}{2} + \epsilon_1)(\frac{1}{2} + \epsilon_2)+(\frac{1}{2} - \epsilon_1)(\frac{1}{2} - \epsilon_2)\\
&=\frac{1}{2} + 2\epsilon_1 \epsilon_2.
\end{align*}
By induction $Pr[X_1 \oplus \cdots \oplus X_t = 0] = \frac{1}{2} + 2^{t-1}\prod_{i} \epsilon_i$
\end{itemize}
\subsection*{Attacking a Linear Trail}
\begin{itemize}
\item Four linear approximations with $|\epsilon_i| = 1/4$
\begin{align*}
S_{12} &: X_1 \oplus X_3 \oplus X_4 = Y_2\\
S_{22} &: X_2 = Y_2 \oplus Y_4\\
S_{32} &: X_2 = Y_2 \oplus Y_4\\
S_{24} &: X_2 = Y_2 \oplus Y_4
\end{align*}
Combine them to get:
$$U_{4,6} \oplus U_{4,8} \oplus U_{4,14} \oplus U_{4,16} \oplus P_5 \oplus P_7 \oplus P_8 = \bigoplus K_{i,j}$$
with bias $|\epsilon| = 2^{4-1}(\frac{1}{4})^4 = 2^{-5}$
\item Our expression (with bias $2^{-5}$) links plaintext bits to input bits to the 4\ts{th} round.
\item Partially undo the last round by guessing the last key. Only 2 S-Boxes are involved, i.e., $2^8 = 256$ guesses.
\item For a correct guess, the question holds with bias $2^{-5}$. For a wrong guess, it holds with a bias zero (harmless lie).
\item Required pairs $2^{10} \approx 1000$. Attack complexity $2^{18} \ll 2^{32}$ operations.
\end{itemize}

\subsection*{Linear Cryptanalysis Summary}
\begin{itemize}
\item Linear Cryptanalysis is a \textbf{known plaintext attack}.
\begin{itemize}
\item [$\circ$] Find linear approximation of S-Boxes.
\item [$\circ$] Compute bias of each approximation.
\item [$\circ$] Find linear trails.
\item [$\circ$] Compute bias of linear trails.
\item [$\circ$] Compute data and time complexity.
\item [$\circ$] Estimate key bits from many plaintext-ciphertext pairs.
\end{itemize}
\end{itemize}

\subsection*{Ideal Block Cipher}

\begin{itemize}
\item A function $\epsilon(n)$ is negligible if for every constant $c > 0$, there exists a constant $n_0$, such that $$\epsilon(n) < \frac{1}{n^c}$$ for all $n \geq n_0$.
\item Motivation: Events happening with negligible probability can not be exploited by polynomial time algorithms! (they "never" happen!)
\item Caveat! Theoretic notion. Interpret with care in practice.
\item A function is pseudo-random if no efficient adversary can distinguish between the function and a random function.
\item A family of functions $F: \{0,1\}^k \times \{0,1\}^n \rightarrow \{0,1\}^n$ is pseudo-random if for all polynomial time oracle adversaries $A$
$$\Bigg|\Pr_{K} \Big[A^{F_K(\cdot)}=1 \Big] - \Pr_{R:\{0,1\}^n \rightarrow \{0,1\}^n} \Big[A^{R(\cdot)}=1\Big] \Bigg|$$ is negligible.
\item A permutation and its inverse are pseudo-random if no efficient adversary can distinguish between the permutation and its inverse, and a random permutation and its inverse.
\item A family of permutations $P: \{0,1\}^k \times \{0,1\}^n \rightarrow \{0,1\}^n$ is pseudo-random if for all polynomial time oracle adversaries $A$
$$\Bigg|\Pr_{K} \Big[A^{P_K(\cdot),P_K^{-1}(\cdot)}=1 \Big] - \Pr_{\Pi \in {\mathcal S}_{2^n}} \Big[A^{\Pi(\cdot),\Pi^{-1}(\cdot)}=1\Big] \Bigg|$$ 
is negligible, where ${\mathcal S}_{2^n}$ is the set of permutations of $\{0,1\}^n$.
\end{itemize}

\subsection*{Idealised Four-Round Feistel Network}

\begin{itemize}
\item Feistel round ($H$ for "Horst Feistel").
$$H_{F_K}(L,R) = (R, L \oplus F(R,K))$$
\item Theorem: (Luby and Rackoff) If $F$ is a pseudo-random family of functions, then
$$H_{F_{k_1},F_{k_2},F_{k_3},F_{k_4}}(x) = H_{F_{k_4}}(H_{F_{k_3}}(H_{F_{k_2}}(H_{F_{k_1}}(x))))$$ (and its inverse) is a pseudo-random family of permutations.
\item Why do we need four rounds?
\end{itemize}

\subsection*{Perfect Secrecy}
\begin{itemize}
\item When is a cipher perfectly secure?
\item How should we formalise this?
\item A cryptosystem has perfect secrecy if guessing the plaintext is equally hard to do regardless of whether or not the ciphertext is given.
\item A cryptosystem has perfect secrecy if $$Pr[M = m \mid C = c] = Pr[M = m]$$ for every $m \in {\mathcal M}$ and $c \in {\mathcal C}$, where $M$ and $C$ are random variables taking values over ${\mathcal M}$ and ${\mathcal C}$.
\item Game Based Definition: $Exp_A^b$, where $A$ is a strategy:
\begin{itemize}
\item [$\circ$] $k \leftarrow_R {\mathcal K}$
\item [$\circ$] $(m_0, m_1) \leftarrow A$
\item [$\circ$] $c = E_k(m_b)$
\item [$\circ$] $d\leftarrow A(c)$, with $d \in \{0,1\}$
\item [$\circ$] Output $d$.
\end{itemize}
\item A cryptossystem has perfect secrecy if for every computationally unbounded strategy $A$, $$Pr[Exp_A^0 = 1] = Pr[Exp^1_A = 1].$$
\end{itemize}

\subsection*{One-Time Pad (OTP)}
\begin{itemize}
\item The key is given by a random tuple $k = (b_0, ..., b_{n-1}) \in \mathbb{Z}_{2}^{n}$.
\item The plaintext $m = (m_0, ..., m_{n-1}) \in \mathbb{Z}_{2}^{n}$ gives ciphertext $c = (c_0, ..., c_{n-1})$.
\item Encryption is given by $c_i = m_i \oplus b_i$.
\item Decryption is given by $m_i = c_i \oplus b_i$.
\end{itemize}

\subsection*{Bayes' Theorem and OTP's Perfect Secrecy}
\begin{itemize}
\item If $A$ and $B$ are events and $Pr[B] > 0$, then $$Pr[A \mid B] = \frac{Pr[A]Pr[B \mid A]}{Pr[B]}$$
\item Probabilistic Argument. Bayes implies that:
\begin{align*}
Pr[M = m \mid C = c] &= \frac{Pr[M = m]Pr[C = c \mid M = m]}{Pr[C=c]}\\
&=Pr[M = m]\frac{2^{-n}}{2^{-n}}\\
&=Pr[M=m].
\end{align*}
\item Simulation Argument: The ciphertext is uniformly and independently distributed form the plaintext. We can simulate it on our own!
\item Bad News! "For every cipher with perfect secrecy, the key requires at least as much space to represent as the plaintext."
\begin{itemize}
\item [$\circ$] Dangerous in practice to rely on no reuse of, e.g., file containing randomness!
\end{itemize}
\end{itemize}

\section*{Lecture 5 - Hash Functions \& Random Oracles}

\subsection*{Universal Hash Functions}

\begin{itemize}
\item An ensemble $f = \{f_\alpha\}$ of hash functions $f_\alpha : X \rightarrow Y$ is (strongly) 2-universal if for every $x, x' \in X$ and $y, y' \in Y$ with $x \neq x'$ and a random $\alpha$
$$Pr[f_\alpha(x) = y \land f_\alpha(x') = y'] = \frac{1}{|Y|^2} .$$
I.e., for any fixed $x' \neq x$, the outputs $f_\alpha(x)$ and $f_\alpha(x')$ are uniformly and independently distributed when $\alpha$ is chosen randomly.

In particular $x$ and $x'$ are both mapped to the same value with probability $\frac{1}{|Y|}$.
\item Example: The function $f: \mathbb{Z}_p \rightarrow \mathbb{Z}_p$ for prime $p$ defined by $$f(z) = az + b \mod p$$ is strongly 2-universal
\item Proof: Let $x, x', y, y' \in \mathbb{Z}_p$ with $x \neq x'$. Then 
$$
\begin{pmatrix}
x & 1 \\
x' & 1
\end{pmatrix}
\begin{pmatrix}
z_1 \\
z_2
\end{pmatrix}
=
\begin{pmatrix}
y \\
y'
\end{pmatrix}
$$
has a unique solution. Random $(a,b)$ satisfies this solution with probability $\frac{1}{p^2}$.
\item Universal hash functions are \textbf{not} one-way or collision resistant!
\end{itemize}

\subsection*{Hash Functions}
\begin{itemize}
\item A hash function maps arbitrary long bit strings into strings of fixed length.
\item The output of a hash function should be "unpredictable"
\item The following properties should be met by a hash function:
\begin{itemize}
\item [$\circ$] Finding a pre-image of an output should be hard.
\item [$\circ$] Finding two inputs giving the same output should be hard.
\item [$\circ$] The output of the function should be "random".
\end{itemize}
\item Let $f: \{0,1\}^* \rightarrow \{0,1\}$ be a polynomial time commutable function.
\item We can derive an ensemble $\{f_n\}_{n \in \mathbb{N}}$, with $$f_n: \{0,1\}^n \rightarrow \{0,1\}^*$$ by setting $f_n(x) = f(x)$.
\item Note that we may recover $f$ form the ensemble by $f(x) = f_{|x|}(x)$.
\item When convenient we give definitions for a function, but it can be turned into a definition for an ensemble.
\item Consider $F=\{f_n\}_{n \in \mathbb{N}}$, where $f_n$ is itself an ensemble $\{f_{n,\alpha_n}\}_{\alpha_n \in \{0,1\}^n}$, with $$f_{n,\alpha_n}:\{0,1\}^{l(n)} \rightarrow \{0,1\}^{l'(n)}$$ for some length polynomials $l(n)$ and $l'(n)$.
\item Here $n$ is the security parameter and $\alpha_n$ is a "key" that is chosen randomly.
\item We may also view $F$ as an ensemble $\{f_\alpha\}$, where $f_\alpha = \{f_{n,\alpha_n}\}_{n \in \mathbb{N}}$ and $\alpha = \{\alpha_n\}_{n \in \mathbb{N}}$.
\item These conventions allow us to talk about what in everyday language is a "function" $f$ in several convenient ways.
\item FROM NOW ON WE CAN FORGET THE ABOVE AND ASSUME EVERYTHING WORKS....
\end{itemize}

\subsection*{One-Wayness}
\begin{itemize}
\item Definition: A function $f: \{0,1\}^* \rightarrow \{0,1\}^*$ is said to be one-way if for every polynomial time algorithm $A$ and a random $x$ $$Pr[A(f(x)) = x' \land f(x') = f(x)] < \epsilon(n)$$ for a negligible function $\epsilon$.
\item Normally $f$ is computable in polynomial time in its input size.
\item Definition: A function $h: \{0,1\}^* \rightarrow \{0,1\}^*$ is said to be second pre-image resistant if for every polynomial time algorithm $A$ and a random $x$ $$Pr[A(x) = x' \land x' \neq x \land f(x') = f(x)] < \epsilon(n)$$ for a negligible function $\epsilon$.
\item Note that $A$ is given not only the output of $f$, but also the input $x$, but it must find a second pre-image.
\item Definition: Let $f = \{f_\alpha\}_\alpha$ be an ensemble of functions. the "function" $f$ is said to be collision resistant if for every polynomial time algorithm $A$ and randomly chosen $\alpha$ $$Pr[A(\alpha) = (x,x') \land x \neq x' \land f_\alpha(x') = f_\alpha(x)] < \epsilon(n)$$ for a negligible function $\epsilon$.
\item An algorithm that gets a small "advice string" for each security parameter can easily hardcode a collision for a fixed function $f$, which explains the random index $\alpha$.
\end{itemize}

\subsection*{Relations for Compressing Hash Functions}
\begin{itemize}
\item If a function is not second pre-image resistant, then it is not collision-resistant.
\begin{itemize}
\item [$\circ$] Pick random $x$.
\item [$\circ$] Request second pre-image $x' \neq x$ with $f(x') = f(x)$.
\item [$\circ$] Output $x'$ and $x$.
\end{itemize}
\item If a function is not one-way, then it is not second pre-image resistant.
\begin{itemize}
\item [$\circ$] Given a random $x$, compute $y = f(x)$.
\item [$\circ$] Request pre-image $x'$ of $y$.
\item [$\circ$] Repeat until $x' \neq x$, and output $x'$.
\end{itemize}
\end{itemize}

\subsection*{Random Oracles}

\begin{itemize}
\item A random oracle is simply a randomly chosen function with appropriate domain and range.
\item A random oracle is the perfect hash function. Every input is mapped independently and uniformly in the range.
\item Let us consider how a random oracle behaves with respect to our notions of security of hash functions.
\end{itemize}

\subsection*{Pre-Image of Random Oracle}

\begin{itemize}
\item We assume with little loss that an adversary always "knows" if it has found a pre-image, i.e., it queries the random oracle on its output. 
\item Theorem: Let $H: X \rightarrow Y$ be a randomly chosen function and let $x \in X$ be randomly chosen. Then for every algorithm $A$ making $q$ oracle queries
$$Pr[A^{H(\cdot)}(H(x)) = x' \land H(x) = H(x')] \leq 1 - \bigg(1 - \frac{1}{|Y|} \bigg)^q .$$
\item Proof: Each query $x'$ satisfies $H(x') \neq H(x)$ independently with probability $1 = \frac{1}{|Y|}$.
\end{itemize}

\subsection*{Second Pre-Image of Random Oracle}

\begin{itemize}
\item We assume with loss that an adversary always "knows" if it has found a second pre-image, i.e., it quries the random oracle on the input and its output.
\item Theorem: Let $H: X \rightarrow Y$ be a randomly chosen function and let $x \in X$ be randomly chosen. Then for every such algorithm $A$ making $q$ oracle queries
$$Pr[A^{H(\cdot)}(x) = x' \land x \neq x' \land H(x) = H(x')] \leq 1 - \bigg(1 - \frac{1}{|Y|} \bigg)^{q-1} .$$
\item Proof: Same as pre-image case, except we must waste one query on the input value to get the target in $Y$.
\end{itemize}

\subsubsection*{Collision Resistance of Random Oracles}

\begin{itemize}
\item We assume with little loss that and adversary always "knows" if it has found a collision, i.e. it queries the random oracle on its outputs.
\item Theorem: Let $H: X \rightarrow Y$ be a randomly chosen function and let $x \in X$ be randomly chosen. Then for every such algorithm $A$ making $q$ oracle queries
$$Pr[A^{H(\cdot)} = (x, x') \land x \neq x' \land H(x) = H(x')] \leq 1 - \prod_{i=1}^{q-1} \bigg(1 - \frac{i}{|Y|} \bigg)$$

$$Pr[A^{H(\cdot)} = (x, x') \land x \neq x' \land H(x) = H(x')] \leq \frac{q(q-1)}{2|Y|} .$$

\item Proof: $1 - \frac{i-1}{|Y|}$ bounds the probability that the $i\ts{th}$ query does not give a collision for any of the $i-1$ previous queries, conditioned on no previous collisions. 
\end{itemize}

\section*{Lecture 6 - Hash Functions and MACs}

\subsection*{Iterated Hash Functions (Merkle-Damg\aa rd)}

\begin{itemize}
\item Suppose that we are given a collision resistant hash function $$f: \{0,1\}^{n+t} \rightarrow \{0,1\}^n.$$
\item How can we construct a collision resistant hash function $$f: \{0,1\}^* \rightarrow \{0,1\}^n$$ mapping any length inputs?
\item Construction:
\begin{itemize}
\item [$\circ$] Let $x=(x_1, ..., x_k)$ with $|x_i| = t$ and $0<|x_k| \leq t$.
\item [$\circ$] Let $x_{k+1}$ be the total number of bits in $x$.
\item [$\circ$] Pad $x_k$ with zeros until it has length $t$.
\item [$\circ$] $y_0 = 0^n, y_i= f(y_{i-1}, x_i)$ for $i = 1,..., k+1$.
\item [$\circ$] Output $y_{k+1}$
\end{itemize}
\item Here the total number of bits is bounded by $2^t-1$, but this can be relaxed.
\item Suppose $A$ finds collisions in Merkle-Damg\aa rd.
\begin{itemize}
\item [$\circ$] If the number of bits differ in a collision, then we can derive a collision from the last invocation of $f$.
\item [$\circ$] If not, then we move backwards until we get a collision. Since both inputs have the same length, we are guaranteed to find a collision.
\end{itemize}
\end{itemize}

\subsection*{Standardised Hash Functions}

\begin{itemize}
\item Despite that theory says it is impossible, in practice people simply live with \textbf{fixed} hash functions and use them as if they are randomly chosen functions. 
\item \textbf{SHA}
\begin{itemize}
\item [$\circ$] Secure Hash Algorithm (SHA-0,1, and the SHA-2 family) are hash functions standardised by NIST to be used in, e.g., signature schemes and random number generation. 
\item [$\circ$] SHA-0 was weak and withdraws by NIST. SHA-1 was withdrawn 2010. The SHA-2 family is based on similar ideas but seems safe so far.
\item [$\circ$] All are iterated hash functions, starting from a basic compression function.
\end{itemize}
\item \textbf{SHA-3}
\begin{itemize}
\item [$\circ$] NIST ran an open competition for the next hash function, named SHA-3. Several groups of famous researchers submitted proposals. 
\item [$\circ$] Call for SHA-3 explicitly asked for "different" hash functions. 
\item [$\circ$] The competition ended on October 2, 2012, and the hash function Keccak was selected as the winner.
\item [$\circ$] It was constructed by Guido Bertoni, Joan Daemen, Micha\"el Peeters, and Gilles Van Assche.
\end{itemize}
\end{itemize}

\subsection*{Message Authentication Codes (MACs)}

\begin{itemize}
\item Message Authentication Codes (MACs) are used to ensure integrity and authentication of messages.
\item Scenario:
\begin{itemize}
\item [$\circ$] Alice and Bob share a common key $k$.
\item [$\circ$] Alice computes an authentication tag $\alpha = MAC_k(m)$ and sends $(m,\alpha)$ to Bob.
\item [$\circ$] Bob receives $(m',\alpha')$ form Alice, but before accepting $m'$ as coming from Alice, Bob checks that $MAC_k(m')=\alpha'$.
\end{itemize}
\end{itemize}

\subsubsection*{Security of a MAC}
\begin{itemize}
\item A message authentication code MAC is secure if for a random key $k$ and every polynomial time algorithm $A$,
$$Pr[A^{MAC_k(\cdot)}=(m,\alpha) \land MAC_k(m) = \alpha \land \forall i : m \neq m_i]$$
is negligible, where $m_i$ is the $i$\ts{th} query to the oracle $MAC_k(\cdot)$.
\end{itemize}

\subsubsection*{Random Oracle As MAC}

\begin{itemize}
\item Suppose that $H: \{0,1\}^* \rightarrow \{0,1\}^n$ is a random oracle.
\item Then we can construct a MAC as $MAC_k(m) = H(k,m)$.
\item Could we plug in an iterated hash function in place of the random oracle?
\end{itemize}

\subsection*{HMAC}

\begin{itemize}
\item Let $H: \{0,1\}^* \rightarrow \{0,1\}^n$ be a "cryptographic hashfunction", e.g. SHA-256.
\item $HMAC_{k_1, k_2}(x) = H\big(k_2||H(k_1||x)\big)$
\item This is provably secure under the assumption that
\begin{itemize}
\item [$\circ$] $H(k_1||\cdot)$ is unknown-key collision resistant, and
\item [$\circ$] $H(k_2||\cdot)$ is a secure MAC for fixed-size messages.
\end{itemize}
\end{itemize}

\section*{Lecture 7 - MACs and Information Theory}

\subsection*{MACs}

\subsubsection*{CBC-MAC}

\begin{itemize}
\item Let $E$ be a secure block-cipher, and $x = (x_1,...,x_t)$ an input. The MAC-key is simply the block-cipher key.
\begin{itemize}
\item [$\circ$] $y_0 = 000...0$
\item [$\circ$] For $i=1,...,t$, $y_i = E_k(y_{i-1}\oplus x_i)$
\item [$\circ$] Return $y_t$.
\end{itemize}
\item Is this secure?
\end{itemize}

\subsubsection*{Universal Hashfunction As MAC}
\begin{itemize}
\item Theorem: A $t$-universal hashfunction $f_\alpha$ for a randomly chosen secret $\alpha$ is an \textbf{unconditionally secure} MAC, provided that the number of queries is smaller than $t$.
\end{itemize}

\subsection*{Information Theory}

\begin{itemize}
\item Information theory is a mathematical theory of communication.
\item Typical questions studied are how to compress, transmit, and store information.
\item Information theory is also useful to argue about some cryptographic schemes and protocols.
\item Memory Source Over Finite Alphabet: A source produces symbols from an alphabet $\Sigma = \{a_1,...,a_n\}$. Each generated symbol is independently distributed.
\item Binary Channel: A binary channel can (only) send bits. \item Coder/Decoder: Our goal is to come up with a scheme to:
\begin{itemize}
\item [$\circ$] Convert a symbol $a$ from the alphabet $\Sigma$ into a sequence $(b_1,...,b_l)$ of bits, 
\item [$\circ$] send the bits over the channel, and
\item [$\circ$] decode the sequence into $a$ again at the receiving end.
\end{itemize}
\item Optimisation goal: We want to minimise the \textbf{expected} number of bits/symbols we send over the binary channel, i.e., if $X$ is a random variable over $\Sigma$ and $l(x)$ is the length of the codeword of $x$ then we wish to minimise.
$$E[l(X)] = \sum_{x\in \Sigma}P_X(x)l(x).$$
\end{itemize}

\subsubsection*{Examples}
\begin{itemize}
\item $X$ takes values in $\sigma = \{a, b, c, d\}$ with uniform distribution. How would you encode this?
\item $X$ takes values in $\sigma = \{a,b,c\}$, with $P_X(a) = \frac{1}{2}$, $P_X(b) = \frac{1}{4}$, and $P_X(c) = \frac{1}{4}$. How would you encode this?
\item It seems we need $l(x) = \log |\Sigma|$. This gives the Hartley measure.
\item It seems we need $l(x) = \log\frac{1}{P_X(x)}$ bits to encode $x$.
\item Let us turn this expression into a definition.
\item Let $X$ be a random variable taking values in $\mathcal{X}$. Then the entropy of $X$ is $$H(X) = - \sum_{x\in\Sigma}P_X(x)\log P_X(x).$$
\item Examples and intuition are nice, but what we need is a theorem that states that this is \textbf{exactly} the right length of an optimal code.
\end{itemize}

\subsubsection*{Jensen's Inequality}

\begin{itemize}
\item Definition: A function $f: \mathcal{X} \rightarrow (a,b)$ is \textbf{concave} if $$\lambda \cdot f(x) + (1-\lambda)f(y) \leq f(\lambda \cdot x + (1- \lambda)y),$$ for every $x, y \in (a,b)$ and $0\leq\lambda\leq 1$.
\item Theorem: Suppose $f$ is continuous and strictly concave on $(a,b)$, and $X$ is a discrete random variable. Then $$E[f(X)] \leq f(E[X]),$$ with equality if and only if $X$ is constant.
\item Proof idea: Consider two points + induction over number of points.
\end{itemize}

\subsubsection*{Kraft's Inequality}

\begin{itemize}
\item Theorem: There exists a prefix-free code $E$ with codeword lengths $l_x$, for $x\in \Sigma$ if and only if $$\sum_{x\in\Sigma}2^{-l_x}\leq 1.$$
\item Proof Sketch: Given a prefix-fee code, we consider the corresponding binary tree with codewords at the leaves. We may "fold" it by replacing two siblings leaves $E(x)$ and $E(y)$ by $(xy)$ with length $l_x-1$. Repeat.
\item Given lengths $l_{X_1} \leq l_{X_1} \leq ... \leq l_{X_n}$ we start with the complete binary tree of depth $l_{X_n}$ and prune it.
\end{itemize}

\subsubsection*{Binary Source Coding Theorem}
\begin{itemize}
\item Theorem: Let $E$ be an optimal code and let $l(x)$ be the length of the codeword of $x$. Then $$H(X)\leq E[l(X)] < H(X) + 1.$$
\item Proof of Upper Bound: Define $l_x = \lceil-\log P_X(x)\rceil$. Then we have
$$\sum_{x\in\Sigma}2^{-l_x} \leq \sum_{x\in\Sigma}2^{\log P_X(x)}=\sum_{x\in\Sigma}P_X(x) = 1$$
Kraft's inequality implies that there is a code with codeword lengths $l_x$. Then note that
$\sum_{x\in\Sigma}P_X(x)\lceil-\log P_X(x)\rceil < H(X) + 1$.
\item Proof of Lower Bound:
\begin{align*}
E[l(X)] &= \sum_x P_X(x)l_x\\
&=-\sum_x P_X(x)\log 2^{-l_x}\\
&\geq -\sum_x P_X(x)\log P_X(x)\\
&= H(X)
\end{align*}
\end{itemize}

\subsubsection*{Huffman's Code}

\begin{algorithmic}[1]
\State \textbf{Input:} $\{(a_1,p_1),...,(a_n,p_n)\}$.
\State \textbf{Output:} $0/1$-labeled rooted tree.
\Procedure{Huffman}{$\{(a_1,p_1),...,(a_n,p_n)\}$}
\State $S\gets \{(a_1,p_1,a_1), ...,(a_n,p_n,a_n)\}$
\While{$|S| \geq 2$}
\State Find $(b_i,p_i,t_i),(b_j,p_j,t_j) \in S$ with minimal $p_i$ and $p_j$.
\State $S\gets S \setminus \{(b_i,p_i,t_i),(b_j,p_j,t_j)\}$
\State $S\gets S \cup \{\big(b_i || b_j, p_i + p_j, \Call{Node}{t_i,t_j}\big)\}$
\EndWhile
\State \Return $S$
\EndProcedure
\end{algorithmic}

\begin{itemize}
\item Theorem: Huffman's code is optimal.
\item Proof idea: There exists an optimal code where the tow least likely symbols are neighbours.
\end{itemize}

\subsubsection*{Entropy}

\begin{itemize}
\item Let us turn this expression into a definition.
\item Definition: Let $X$ be a random variable taking values in $\mathcal{X}$. Then the \textbf{entropy} of $X$ is $$H(X) = - \sum_{x\in\mathcal{X}} P_X(x)\log P_X(x).$$
\end{itemize}

\subsubsection*{Conditional Entropy}

\begin{itemize}
\item Definition: Let $(X,Y)$ be a random variable taking values in $\mathcal{X} \times \mathcal{Y}$. We define \textbf{conditional entropy}
\begin{align*}
H(X|y) &= - \sum_x P_{X|Y}(x|y)\log P_{X|Y}(x|y) \text{\quad and}\\
H(X|Y) &= \sum_y P_Y(y)H(X|y)
\end{align*}
\item Note that $H(X|y)$ is simply the ordinary entropy function of a random variable with probability function $P_{X|Y}(\cdot|y)$.
\end{itemize}

\subsubsection*{Properties of Entropy}

\begin{itemize}
\item Let $X$ be a random variable taking values in $\mathcal{X}$.
\item Upper Bound: $H(X) = E[-\log P_X(X)] \leq \log |\mathcal{X}|$.
\item Chain Rule and Conditioning:
\begin{align*}
H(X,Y) &= -\sum_{x,y}P_{X,Y}(x,y) \log P_{X,Y}(x,y)\\
&= - \sum_{x,y}P_{X,Y}(x,y)\big(\log P_Y(y) + \log P_{X|Y} (x|y)\big)\\
&= - \sum_y P_Y(y)\log P_Y(y) - \sum_{x,y} P_{X,Y}(x,y) \log P_{X|Y}(x|y)\\
&= H(Y) + H(X|Y) \leq H(Y) + H(X)
\end{align*}
\end{itemize}

\section*{Lecture 8 - Elementary Number Theory}

\subsection*{Greatest Common Divisors}

\begin{itemize}
\item Definition: A common divisor of two integers $m$ and $n$ is an integer $d$ such that $d \mid m$ and $d \mid n$.
\item Definition: A greatest common divisor (GCD) of two integers $m$ and $n$ is a common divisor $d$ such that every common divisor $d'$ divides $d$.
\item The GCD is the positive GCD.
\item We denote the GCD of $m$ and $n$ by gcd($m,n$).
\item Properties:
\begin{itemize}
\item [$\circ$] gcd($m,n$) = gcd($n,m$)
\item [$\circ$] gcd($m,n$) = gcd($m-n,n$) if $m \geq n$
\item [$\circ$] gcd($m,n$) = gcd($m \mod n,n$)
\item [$\circ$] gcd($m,n$) = 2 gcd($m/2,n/2$) if $m$ and $n$ are even.
\item [$\circ$] gcd($m,n$) = gcd($m/2,n$) if $m$ is even and $n$ is odd.
\end{itemize}
\end{itemize}

\subsubsection*{Euclidean Algorithm}

\begin{algorithmic}[1]
\Procedure{Euclidean}{$m,n$}
\While{$n \neq 0$}
\State $t \gets n$
\State $n \gets m \mod n$
\State $m \gets t$
\EndWhile
\State \Return $m$
\EndProcedure
\end{algorithmic}

\subsubsection*{Steins Algorithm (Binary GCD Algorithm)}

\begin{algorithmic}[1]
\Procedure{Stein}{$m,n$}
\If{$m = 0$ or $n =0$} \Return $0$ \EndIf
\State $s \gets 0$
\While{$m$ and $n$ are even}
\State $m \gets m/2$
\State $n \gets n/2$
\State $s \gets s+1$
\EndWhile
\While{$n$ is even}
\State $n \gets n/2$
\EndWhile
\While{$m \neq 0$}
\While{$m$ is even}
\State $m \gets m/2$
\EndWhile
\If{$m < n$}
\State \Call{Swap}{m,n}
\EndIf
\State $m \gets m-n$
\State $m \gets m/2$
\EndWhile
\State \Return $2^s n$
\EndProcedure
\end{algorithmic}

\subsubsection*{Bezout's Lemma}

\begin{itemize}
\item Lemma: There exists integers $a$ and $b$ such that $$\text{gcd}(m,n) = am + bn.$$
\item Proof: Let $d > \text{gcd}(m,n)$ be the smallest positive integer of the form $d = am + bn.$ Write $m = cd + r$ with $0<r<d$. Then 
\begin{align*}
d > r &= m - cd\\
&= m-c(am + bn)\\
&= (1-ca)m + (-cb)n,
\end{align*}
a contradiction! Thus, $r = 0$ and $d \mid m$. Similary, $d \mid n$.
\end{itemize}


\subsubsection*{Extended Euclidean Algorithm (Recursive Version)}

\begin{algorithmic}[1]
\Procedure{ExtendedEuclidean}{$m,n$}
\If{$m \mod n = 0$}
\State \Return $(0,1)$
\Else
\State $(x,y) \gets \Call{ExtendedEuclidean}{n, m \mod n}$
\State \Return $(y, x - y \lfloor m / n \rfloor)$
\EndIf
\EndProcedure
\end{algorithmic}

\begin{itemize}
\item If $(x,y) \gets \Call{ExtendedEuclidean}{m,n}$ then  $\text{gcd}(m,n) = xm + yn$.
\end{itemize}

\subsection*{Coprimality (Relative Primality)}

\begin{itemize}
\item Definition: Two integers $m$ and $n$ are coprime if their greatest common divisor is 1.
\item Fact: If $a$ and $n$ are coprime, then there exists a $b$ such that $ab = 1 \mod n$.
\end{itemize}

\subsection*{Chinese Remainder Theorem (CRT)}

\begin{itemize}
\item Theorem: (Sun Tzu 400 AC) Let $n_1,...,n_k$ be positive pairwise coprime integers and let $a_1,...,a_k$ be integers. Then the equation system
\begin{align*}
x &= a_1 \mod n_1\\
x &= a_2 \mod n_2\\
x &= a_3 \mod n_3\\
&\vdotswithin{=} \\
x &= a_k \mod n_k
\end{align*}
has a unique solution in $\{0,...,\prod_{i}n_i-1\}$.
\end{itemize}

\subsection*{Constructive Proof of CRT}

\begin{itemize}
\item Set $N = n_1 \cdot n_2 \cdot ... \cdot n_k$.
\item Find $r_i$ and $s_i$ such that $r_i n_i + s_i \frac{N}{n_i} = 1$ (Bezout).
\item Note that $$s_i\frac{N}{n_i} = 1 - r_i n_i = 
\begin{cases}
1 \mod n_i \\
0 \mod n_j & \text{if $j \neq i$}
\end{cases}$$
\item The solution to the equation system becomes:
$$x = \sum_{i=1}^{k}\bigg(s_i\frac{N}{n_i}\bigg) \cdot a_i$$
\end{itemize}

\subsection*{The Multiplicative Group}

\begin{itemize}
\item The set $\mathbb{Z}_n^* = \{0 \leq a < n : \text{gcd}(a,n) =1 \}$ forms a group, since:
\begin{itemize}
\item [$\circ$] Closure: It is closed under multiplication modulo $n$.
\item [$\circ$] Associativity: For $x,y,z \in \mathbb{Z}_n^*:$ $$(xy)z = x(yz) \mod n.$$
\item [$\circ$] Identity: For every $x \in \mathbb{Z}_n^*:$ $$1 \cdot x = x \cdot 1 = x.$$
\item [$\circ$] Inverse: For every $a \in \mathbb{Z}_n^*$ there exists $b \in \mathbb{Z}_n^*$ such that: $$ab = 1 \mod n.$$
\end{itemize}
\end{itemize}

\subsection*{Lagrange's Theorem}

\begin{itemize}
\item Theorem: If $H$ is a subgroup of a finite group $G$, then $|H|$ divides $|G|$.
\item Proof: Define $aH = \{ah : h \in H\}$. This gives an equivalence relation $x \approx y \iff x = yh \land h \in H$, and a partition of $G$.
\item The map $\phi_{a,b}: aH \rightarrow bH$, defined by $\phi_{a,b}(x) = ba^{-1}x$ is a bijection, so $|aH| = |bH|$ for $a,b \in G$.
\end{itemize}

\subsection*{Euler's Phi-Function (Totient Function)}

\begin{itemize}
\item Definition: Euler's Phi-function $\phi(n)$ counts the number of integers $0<a<n$ relatively prime to $n$.
\begin{itemize}
\item [$\circ$] Clearly: $\phi(p) = p-1$ when $p$ is prime.
\item [$\circ$] Similarly: $\phi(p^k) = p^k - p^{k-1}$ when $p$ is prime and $k>1$.
\item [$\circ$] In general $\phi\Big(\prod_i^{k_i}\Big) = \prod_i\Big(p_i^k - p_i^{k-1}\Big)$.
\end{itemize}
\item How does this follow from CRT?
\begin{itemize}
\item [$\circ$] $\mathbb{Z}_n \simeq \prod_i \mathbb{Z}_{p_i^{k_i}}$ (CRT is a bijection)
\item [$\circ$] If $a \in \mathbb{Z}_n^*$, then $a \mod p_i^{k_i} \in \mathbb{Z}_{p_i^{k_i}}$ (aligns bijection on subsets)
\end{itemize}
\end{itemize}

\subsection*{Fermat's and Euler's Theorems}

\begin{itemize}
\item Theorem: (Fermat) If $b \in \mathbb{Z}_p^*$ and $p$ is prime, then $b^{p-1} = 1 \mod p$.
\item Theorem: (Euler) If $b \in \mathbb{Z}_n^*$, then $b^{\phi(n)} = 1 \mod n.$
\item Proof: Note that $|\mathbb{Z}_n^*| = \phi(n)$. $b$ generates a subgroup $\langle b\rangle$ of $\mathbb{Z}_n^*$, so $|\langle b\rangle|$ divides $\phi(n)$ by Lagrange's theorem and $b^{|\langle b\rangle|} = 1 \mod n$.
\end{itemize}

\subsection*{Multiplicative Group of a Prime Order Field}

\begin{itemize}
\item Definition: A group $G$ is called cyclic if there exists an element $g$ such that each element in $G$ is of the form $g^x$ for some integer $x$.
\item Theorem: If $p$ is prime, then $\mathbb{Z}_p^*$ is cyclic.
\item Every group of pime order is cyclic. Why?\\Keep in mind the difference between:
\begin{itemize}
\item [$\circ$] $\mathbb{Z}_p$ with \textit{prime order} as an \textit{additive group},
\item [$\circ$] $\mathbb{Z}_p^*$ with \textit{non-prime order} as a \textit{multiplicative group}.
\item [$\circ$] Group $G_p$ of \textit{prime order}.
\end{itemize}
\end{itemize}

\section*{Lecture 9 - Public-Key Cryptography}

Public-key cryptography was discovered:

\begin{itemize}
\item By Ellis, Cocks, and Williamson at the Government Communications Headquareters (GCHQ) in the UK in the early 1970s (not public until 1997).
\item Independently by Merkle in 1974 (Merkle's puzzles).
\item Independently in its discrete-logarithm based for by Diffie and Hellman in 1977, and instantiated in 1978 (key-exchagne).
\item Independently in its factoring-based form by Rivest, Shamir and Adlemand in 1977.
\end{itemize}

\begin{itemize}
\item Alice encrypts a message $m$ using Bob's public key pk and encryption algorithm $E$ such that $c = E_{\text{pk}}(m)$. Bob decrypts the ciphertext $c$ using his secret key sk and decryption algorithm  $D$ such that $m = E_{\text{sk}}(c)$.
\item Definition: Mathematically, a public-key cryptosystem can be defined as a tuple $({\mathcal Gen}, E, D)$ where:

\begin{itemize}
\item [$\circ$] ${\mathcal Gen}$ is a probabilistic key generation algorithm that outputs key pairs (pk, sk),
\item [$\circ$] $E$ is a (possibly probabilistic) encryption algorithm that given a public key pk and a message $m$ in the plaintext space ${\mathcal M}_{\text{pk}}$ outputs a ciphertxt $c$, and
\item [$\circ$] $D$ is a decryption algorithm that given a secret key sk and a ciphertext $c$ outputs a plaintext $m$, 
\end{itemize}
such that $D_{\text{sk}}(E_{\text{pk}}(m)) = m$ for every (pk, sk) and $m \in \mathcal {M}_{pk}$.
\end{itemize}

\subsection*{RSA}

\begin{itemize}
\item Key Generation:
\begin{itemize}
\item [$\circ$] choose $n/2$-bit primes $p$ and $q$ randomly and define $N = pq$.
\item [$\circ$] Choose $e$ in $\mathbb{Z}_{\phi(N)}^*$ and compute $d = e^{-1}\mod \phi(N)$.
\item [$\circ$] Output the key pair $((N,e), (p,q,d))$, where $(N,e)$ is the public key and $(p,q,d)$ is the secret key.
\end{itemize}
\item Encryption: Encrypt a plaintext $m \in \mathbb{Z}_N^*$ by computing $$c = m^e \mod N.$$
\item Decryption: Decrypt a ciphertext $c$ by computing $$m = c^d \mod N.$$
\end{itemize}

\subsubsection*{Why does it work?}

\begin{align*}
(m^e \mod N)^d \mod N &= m^{ed} \mod N \\
&= m^{1+t \phi(N)} \mod N \\
&= m^1 \cdot \Big(m^{\phi(N)}\Big)^t \mod N \\
&= m \cdot 1^t \mod N \\
&= m \mod N
\end{align*}

\subsubsection*{Implementing RSA}

\begin{itemize}
\item Modular arithmetic
\item Greatest common divisor
\item Primality test
\end{itemize}

\subsubsection*{Modular Arithmetic}

\begin{itemize}
\item Basic operations on $\mathcal{O}(n)$-bit integers using "text book" implementations.
\begin{tabular}{l c}
Operation & Running time \\\hline
Addition & $\mathcal{O}(n)$ \\
Subtraction & $\mathcal{O}(n)$ \\
Multiplication & $\mathcal{O}(n^2)$ \\
Modular reduction & $\mathcal{O}(n^2)$ \\
Greatest common divisor & $\mathcal{O}(n^2)$
\end{tabular}
\item Optimal algorithms for multiplication and modular reduction are much faster.
\item What about modular exponentiation?
\end{itemize}

\subsubsection*{Square-and-Multiply}

\begin{algorithmic}[1]
\Procedure{SquareAndMultiply}{$x,e,N$}
\State $z \gets 1$
\State $i$ = index of most signifiant one
\While{$i\geq 0$}
\State $z \gets z \cdot z \mod N$
\If{$e_i = 1$}
\State $z \gets z \cdot x \mod N$
\EndIf
\State $i \gets i - 1$
\EndWhile
\State \Return $z$
\EndProcedure
\end{algorithmic}

\begin{itemize}
\item Although basically the same, the most efficient algorithms for exponentiation are faster.
\item Computing $g^{x_1},...,g^{x_k}$ can be done much faster!
\item Computing $\prod_{i \in [k]} g^{x_i}$ can be done much faster!
\item Computing $g_1^x,...,g_k^x$ can be done somewhat faster!
\item What about side-channel attacks?
\end{itemize}

\subsubsection*{Prime Number Theorem}

\begin{itemize}
\item The primes are relatively dense.
\item Theorem: Let $\pi(m)$ denote the number of primes $0<p\leq m$. Then 
$$\lim_{m \rightarrow \infty} \frac{\pi(m)}{\frac{m}{\ln m}} = 1.$$
\item To generate a random prime, we repeatedly pick a random integer $m$ and check if it is prime. It should be prime with probability $1/\ln m$ in a sufficiently large interval.
\end{itemize}

\subsubsection*{Legendre Symbol}

\begin{itemize}
\item Definition: Given an odd integer $b \geq 3$, an integer $a$ is called a quadratic residue modulo $b$ if there existst and integer $x$ such that $a = x^2 \mod b$.
\item Definition: The Legendre Sybol of an integer $a$ modulo an odd prime $p$ is define by
$$\bigg(\frac{a}{p}\bigg) = 
\begin{cases}
\ \ 0 & \text{if $a=0$} \\
\ \ 1 & \text{if $a$ is a quadratic residue modulo $p$} \\
-1 & \text{if $a$ is a quadratic non-residue modulo $p$}
\end{cases}$$
\item Theorem: If $p$ is an odd prime, then 
$$\bigg(\frac{a}{p}\bigg) = a^{(p-1)/2} \mod p$$
\item Proof:
\begin{itemize}
\item [$\circ$] If $a = y^2 \mod p$, then $a^{(p-1)/2} = y^{p-1} = 1 \mod p$.
\item [$\circ$] If $a^{(p-1)/2} = 1 \mod p$ and $b$ generates $\mathbb{Z}_p^*$, then $a^{(p-1)/2} = b^{x(p-1)/2} = 1 \mod p$ for some $x$. Since $b$ is a generator, $(p-1) \mid x(p-1)/2$ and $x$ must be even.
\item [$\circ$] If $a$ is a non-residue, then $a^{(p-1)/2} \neq 1 \mod p$, but $\big(a^{(p-1)/2}\big)^2 = 1 \mod p$, so $a^{(p-1)/2} = -1 \mod p$.
\end{itemize}
\end{itemize}

\subsubsection*{Jacobi Symbol}

\begin{itemize}
\item Definition: The Jacobi Symbol of an integer $a$ modulo an odd integer $b = \prod_i p_i^{e_i}$, with $p_i$ prime, is defined by $$\bigg(\frac{a}{b}\bigg) = \prod_i \bigg(\frac{a}{p_i}\bigg)^{e_i}.$$
\item Note that we can have $\big(\frac{a}{b}\big) = 1$ even when $a$ is a non-residue modulo $b$.
\item Basic Properties:
\begin{align*}
\bigg(\frac{a}{b}\bigg) &= \bigg(\frac{a \mod b}{b}\bigg) \\
\bigg(\frac{ac}{b}\bigg) &= \bigg(\frac{a}{b}\bigg) \bigg(\frac{a}{b}\bigg) .
\end{align*}
\item Law of Quadratic Reciprocity: If $a$ and $b$ are odd integers, then
$$\bigg(\frac{a}{b}\bigg) = (-1)^{\frac{(a-1)(b-1)}{4}} \bigg(\frac{b}{a}\bigg) .$$
\item Supplementary Laws: If $b$ is an odd integer, then
$$\bigg(\frac{-1}{b}\bigg) = (-1)^{\frac{b-1}{2}} \text{\ and \ } \bigg(\frac{2}{b}\bigg) = (-1)^{\frac{b^2-1}{8}} .$$
\end{itemize}

\subsubsection*{Computing the Jacobi Symbol}

The following assumes that $a \geq 0$ and that $b \geq 3$ is odd.

\begin{algorithmic}[1]
\Procedure{Jacobi}{$a,b$}
\If{$a<2$}
\State \Return $a$
\EndIf
\State $s \gets 1$
\While{$a$ is even}
\State $s \gets s \cdot (-1)^{\frac{1}{8}(b^2-1)}$
\State $a \gets a/2$
\EndWhile
\If{$a<b$}
\State \Call{Swap}{$a,b$}
\State $s \gets s \cdot (-1)^{\frac{1}{4}(a-b)(b-1)}$
\EndIf
\State \Return $s \cdot \Call{Jacobi}{a \mod b, b}$
\EndProcedure
\end{algorithmic}

\subsubsection*{Solovay-Strassen Primality Test}

The following assumes that $n \geq 3$.

\begin{algorithmic}[1]
\Procedure{SolovayStrassen}{$n,r$}
\For{$i=1$ \textbf{to} $r$}
\State Choose $0 < a < n$ randomly.
\If{$\big(\frac{a}{n}\big) = 0$ or $\big(\frac{a}{n}\big) \neq a^{(n-1)/2} \mod n$}
\State \Return \textit{composite}
\EndIf
\EndFor
\State \Return \textit{probably prime}
\EndProcedure
\end{algorithmic}

\begin{itemize}
\item Analysis: If $n$ is prime, then $0 \neq \big(\frac{a}{n}\big) = a^{(n-1)/2} \mod n$ for all $0 < a < n$, so we never claim that a prime is composite.
\item If $\big(\frac{a}{n}\big) = 0$, then $\big(\frac{a}{p}\big) = 0$ for some prime factor $p$ of $n$. Thus, $p \mid a$ and $n$ is composite, so we never wrongly return from within the loop.
\item At most half of all elements $a$ in  $\mathbb{Z}_n^*$ have the property that $$\bigg(\frac{a}{n}\bigg) = a^{(n-1)/2} \mod n.$$
\end{itemize}

\subsubsection*{More On Primality Tests}

\begin{itemize}
\item The Miller-Rabin test is faster.
\item Testing many primes can be done faster than testing each separately
\item Those are \textit{probabilistic} primality tests, but there is a \textit{deterministic} test, so primes are in \P.
\end{itemize}

\subsection*{Security of RSA}

\subsubsection*{Factoring}

\begin{itemize}
\item The obvious way to break RSA is to factor the public modulus $N$ and recover the prime factors $p$ and $q$.
\begin{itemize}
\item [$\circ$] The number of field sieve factors $N$ in time 
$$\mathcal{O}\bigg(e^{(1.92+o(1)) \big((\ln N)^{1/3}+ (\ln \ln N)^{2/3}\big)} \bigg) .$$
\item [$\circ$] The elliptic curve method factors $N$ in time
$$\mathcal{O}\bigg(e^{(1+o(1))\sqrt{2\ln p \ln\ln p}}\bigg) .$$
\end{itemize}
\item Note that the latter only depends on the size of $p$!
\end{itemize}

\subsubsection*{Small Encryption Exponents}

\begin{itemize}
\item Suppose that $e=3$ is used by all parties as an encryption exponent.
\begin{itemize}
\item [$\circ$] Small Message: If $m$ is small, then $m^e < N$. Thus, no reduction takes place, and $m$ can be computed in $\mathbb{Z}$ by taking the $e$\ts{th} root.
\item [$\circ$] Identical Plaintexts: If a message $m$ is encrypted under moduli $N_1, N_2, N_3,$ and $N_4$ as $c_1, c_2, c_3,$ and $c_4$, then CRT implies a $c \in \mathbb{Z}_{N_1N_2N_3N_4}$ such that $c=c_i \mod N_i$ and $c = m^e \mod N_1N_2N_3N_4$ with $m < N_i$.
\end{itemize}
\end{itemize}

\subsubsection*{Additional Caveats}

\begin{itemize}
\item Identical Moduli: If a message $m$ is encrypted as $c_1$ and $c_2$ using distinct encryption exponents $e_1$ and $e_2$ with gcd($e_1,e_2$) = 1, and a modulus $N$, then we can find $a,b$ such that $ae_1 + be_2 = 1$ and $m = c_1^ac_2^b \mod N$.
\item Reiter-Franklin Attack: If $e$ is small enough then encryptions of $m$ and $f(m)$ for a polynomial $f \in \mathbb{Z}_N[x]$ allows efficient computation of $m$.
\item Wiener's Attack: If $3d < N^{1/4}$ and $q<p<2q$, then $N$ can be factored in polynomial time with good probability. 
\end{itemize}

\subsubsection*{Factoring From Order of Multiplicative Group}

\begin{itemize}
\item Given $N$ and $\phi(N)$, we can find $p$ and $q$ by solving
\begin{align*}
N &= pq \\
\phi(N) &= (p-1)(q-1)
\end{align*}
\end{itemize}

\section*{Lecture 10 - CPA Security, ROM-RSA, Rabin and Diffie-Hellman}

\subsection*{Factoring from Encryption \& Decryption Exponents}

\begin{itemize}
\item If $N = pq$ with $p$ and $q$ prime, then the CRT implies that $$x^2 = 1 \mod N$$ has four distinct solutions in $\mathbb{Z}_N^*$, and two of these are non-trivial, i.e., distinct from $\pm 1$.
\item If $x$ is a non-trivial root, then $$(x-1)(x+1) = tN$$ but $N \nmid (x-1), (x+1),$ so $$\text{gcd}(x-1,N) > 1 \text{ \ and \ } \text{gcd}(x+1,N) > 1 .$$
\item The encryption \& decryption exponents satisfy $$ed = 1 \mod \phi(N),$$ so if we have $ed - 1 = 2^sr$ with $r$ odd, then
\begin{align*}
(p-1) &= 2^{s_p}r_p \text{ \ which divides \ } 2^sr \text{ \ and \ }\\ 
(q-1) &= 2^{s_q}r_q \text{ \ which divides \ } 2^sr .\\ 
\end{align*}
\item If $v \in \mathbb{Z}_N^*$ is random, then $w = v^r$ is random in the subgroup of elements with order $2^i$ for some $0 \leq i \leq \text{max}\{s_p,s_q\}.$
\item Suppose $s_p \geq s_q$. Then for some $0<i<s_p$, $$w^{2^i} = \pm 1 \mod q$$ and $$w^{2^i} \mod p$$ is uniformly distributed in $\{1,-1\}$.
\item Conclusion: $w^{2^i} (\mod N)$ is a non-trivial root of 1 with probability 1/2, which allows us to factor $N$.
\end{itemize}

\subsection*{CPA Security}

\begin{itemize}
\item RSA clearly provides some kind of "security", but it is clear that we need to be more careful with what we ask for.
\item Intuitively, we want to leak no \textbf{information} of the encrypted plaintext.
\item Intuitively, we want to leak no \textbf{knowledge} of the encrypted plaintext.
\item In other words, no function of the plaintext can efficiently be guessed notably better from its ciphertext than without it.
\item \Call{$\text{Exp}^b_{{\mathcal CS},A}$}{CPA Security Experiment}
\begin{itemize}
\item [$\circ$] Generate Public Key: (pk, sk) $\gets$ Gen($1^n$).
\item [$\circ$] Adversarial Choice of Messages: $(m_0, m_1, s) \gets A(\text{pk})$.
\item [$\circ$] Guess Message: Return the first output of $A(E_{\text{pk}}(m_b), s)$.
\end{itemize}
\item Definition: A cryptosystem ${\mathcal CS} = ({\mathcal Gen}, E, D)$ is said to be CPA secure if for every polynomial time algorithm $A$ $$|Pr[\text{Exp}^0_{{\mathcal CS},A} = 1] - Pr[\text{Exp}^1_{{\mathcal CS},A} = 1]|$$ is negligible.
\item Every CPA secure cryptosystem must be probabilistic!
\item Theorem: Suppose ${\mathcal CS} = ({\mathcal Gen}, E, D)$ is a CPA secure cryptosystem.\\ Then the related cryptosystem where a $t(n)-$list of messages, with $t(n)$ polynomial, is encrypted by repeated independent encryption of each component using the same public key is also CPA secure.
\item CPA security is useful!
\end{itemize}

\subsection*{ROM-RSA}

\begin{itemize}
\item Definition: The RSA assumption states that if:
\begin{itemize}
\item [$\circ$] $N = pq$ factors into two randomly chosen primes $p$ and $q$ of the same bit-size,
\item [$\circ$] $e$ is in $\mathbb{Z}_{\phi(N)}^*$,
\item [$\circ$] $m$ is randomly chosen in $\mathbb{Z}_N^*$,
\end{itemize}
then for every polynomial time algorithm $A$ $$Pr[A(N,e,m^e \mod N) = m]$$ is negligible. 
\end{itemize}

\subsubsection*{CPA Secure ROM-RSA}

\begin{itemize}
\item Suppose that $f : \{0,1\}^n \rightarrow \{0,1\}^n$ is a randomly chosen function (a random oracle).
\begin{itemize}
\item [$\circ$] Key Generation: Choose a random RSA key pair $((N,e), (p,q,d))$, with $\log_2 N = n$.
\item [$\circ$] Encryption: Encrypt a plaintext $m \in \{0,1\}^n$ by choosing $r\in \mathbb{Z}_N^*$ randomly and computing $$(u,v) = (r^e \mod N, f(r) \oplus m).$$
\item [$\circ$] Decryption: Decrypt a ciphertext $(u,v)$ by $$m = v \oplus f(u^d).$$
\end{itemize}
\item We increase the ciphertext size by a factor of two.
\item Our analysis is in the random oracle model, which is unsound!
\item Solutions: 
\begin{itemize}
\item [$\circ$] Using a "optimal" padding the first problem can be reduced. See standard OAEP+.
\item [$\circ$] Using a scheme with much lower rate, the second problem can be removed.
\end{itemize}
\end{itemize}

\subsection*{Rabin}

\begin{itemize}
\item Key Generation:
\begin{itemize}
\item [$\circ$] Choose $n-$bit primes $p$ and $q$ such that $p,q = 3 \mod 4$ randomly and define $N = pq$.
\item [$\circ$] Output the key pair $(N, (p,q))$, where $N$ is the public key and $(p,q)$ is the secret key.
\end{itemize}
\item Encryption: Encrypt a plaintext $m$ by computing $$c = m^2 \mod N.$$
\item Decryption: Decrypt a ciphertext $c$ by computing $$m = \sqrt{c} \mod N.$$
\item There are four roots, so which one should be used?
\item Suppose $y$ is a quadratic residue modulo $p$.
\begin{align*}
\Big(\pm y^{(p+1)/4}\Big)^2 &= y^{(p+1)/2} \mod p \\
&= y^{(p-1)/2} y \mod p \\
&= \bigg(\frac{y}{p}\bigg) y \\
&= y \mod p
\end{align*}
\item In Rabin's cryptosystem:
\begin{itemize}
\item [$\circ$] Find roots for $y_p = y \mod p$ and $y_q = y \mod q$.
\item [$\circ$] Combine roots to get the four roots modulo $N$. Choose the "right" root and output the plaintext.
\end{itemize}
\end{itemize}

\subsubsection*{Security of Rabin's Cryptosystem}

\begin{itemize}
\item Theorem: Breaking Rabin's cryptosystem is equivalent to factoring.
\item Idea:
\begin{itemize}
\item [$\circ$] Choose random element $r$.
\item [$\circ$] Hand $r^2 \mod N$ to adversary.
\item [$\circ$] Consider outputs $r'$ from the adversary such that $(r')^2 = r^2 \mod N$. then $r' \neq \pm r \mod N$, with probability 1/2, in which cased gcd($r' - r, N$) gives a factor of $N$.
\end{itemize}
\end{itemize}

\subsubsection*{A Goldwasser-Micali Variant of Rabin}

\begin{itemize}
\item Theorem [CG98]: If factoring is hard and $r$ is a random quadratic residue modulo $N$, then for every polynomial time algorithm $A$ $$Pr[A(N,r^2 \mod N) = \text{lsb}(r)]$$ is negligible.
\begin{itemize}
\item [$\circ$] Encryption: Encrypt a plaintext $m \in \{0,1\}$ by choosing a random quadratic residue $r$ modulo $N$ and computing $$(u,v) = r^2 \mod N, \text{lsb}(r) \oplus m).$$
\item [$\circ$] Decryption: Decrypt a ciphertext $(u,v)$ by $$m = v \oplus \text{lsb}(\sqrt{u}) \text{ \ where $\sqrt{u}$ is a qudratic residue.}$$
\end{itemize}
\end{itemize}

\subsection*{Diffie-Hellman}

\begin{itemize}
\item Diffie and Hellman asked themselves: How can two parties efficiently agree on a secret key using only public communication?
\item Construction: Let $G$ be a cyclic group of order $q$ with generator $g$.
\begin{itemize}
\item [$\circ$] Alice picks $a \in \mathbb{Z}_q$ randomly, computes $y_a = g^a$ and hands $y_a$ to Bob.
\item [$\circ$] Bob picks $b \in \mathbb{Z}_q$ randomly, computes $y_b = g^b$ and hands $y_b$ to Alice.
\item [$\circ$] Alice computes $k = y_b^a$. 
\item [$\circ$] Bob computes $k = y_a^b$.
\item [$\circ$] The joint secret key is $k$.
\end{itemize}
\item Problems:
\begin{itemize}
\item [$\circ$] Susceptible to man-in-the-middle attack without authentication.
\item [$\circ$] How do we map a random element $k \in G$ to a random symmetric key in $\{0,1\}^n$?
\end{itemize}
\end{itemize}

\subsubsection*{The El Gamal Cryptosystem}

\begin{itemize}
\item Definition: Let $G$ be a cyclic group of order $q$ with generator $g$.
\begin{itemize}
\item [$\circ$] The key generation algorithm chooses a random element $x \in  \mathbb{Z}_q$ as the private key and defines the public key as $$y = g^x.$$
\item [$\circ$] The encryption algorithm takes a message $m \in G$ and the public key $y$, chooses $r \in \mathbb{Z}_q$, and outputs the pair $$(u,v) = E_y(m,r) = (g^r,y^rm).$$
\item [$\circ$] The decryption algorithm takes a ciphertext $(u,v)$ and the secret key and outputs $$m = D_x(u,v) = vu^{-x}.$$
\end{itemize}
\item El Gamal is essentially Diffie-Hellman + OTP.
\item Homomorhpic property (with public key $y$) $$E_y(m_0,r_0)E_y(m_1,r_1) = E_y(m_0m_1,r_0 +r_1).$$ This property is very important in the construction of cryptographic protocols!
\end{itemize}

\section*{Lecture 11 - Number Theory continued}

\subsection*{Discrete Logarithm}

\begin{itemize}
\item Definition: Let $G$ be a cyclic group of order $q$ and let $g$ be a generator $G$. The discrete logarithm of $y \in G$ in the basis $g$ (written $\log_gy$) is defined as the unique $x \in \{0,1,...,q-1\}$ such that $$y=g^x.$$ Compare with a "normal" logarithm! ($\ln y = x$ iff $y = e^x$).
\item Example: 7 is a generator of $\mathbb{Z}_{12}$ additively, since gcd(7,12) = 1. What is $\log_73$? ($9\cdot 7 = 63 = 3 \mod 12$, so $\log_73 = 9$)
\item Example: 7 is a generator of $\mathbb{Z}_{13}^*$. What is $\log_79$? ($7^4 = 9 \mod 13$, so $\log_79 = 4$) 
\end{itemize}

\subsubsection*{Discrete Logarithm Assumption}

\begin{itemize}
\item Let $G_{q_n}$ be a cyclic group of prime order $q_n$ such that $\lfloor \log_2 q_n \rfloor = n$ for $n = 2,3,4,...,$ and denote the family $\{G_{q_n}\}_{n \in \mathbb{N}}$ by $G$.
\item Definition: The Discrete Logarithm (DL) Assumption in $G$ states that if generators $g_n$ and $y_n$ of $G_{q_n}$ are randomly chosen, then for every polynomial time algorithm $A$ $$Pr[A(g_n, y_n) = \log_{g_n}y_n]$$ is negligible.
\item We usually remove the indices from our notation! $$Pr[A(g,y) = \log_g y]$$
\end{itemize}

\subsubsection*{Diffie-Hellman Assumption}

\begin{itemize}
\item Definition: Let $g$ be a generator of $G$. The Diffie-Hellman (DH) Assumption in $G$ states that if $a,b \in \mathbb{Z}_q$ are randomly chosen, then for every polynomial time algorithm $A$ $$Pr[A(g^a, g^b) = g^{ab}]$$ is negligible.
\end{itemize}

\subsubsection*{Decision Diffie-Hellman Assumption}

\begin{itemize}
\item Definition: Let $g$ be a generator of $G$. The Decision Diffie-Hellman (DDH) Assumption in $G$ states that if $a,b,c \in \mathbb{Z}_q$ are randomly chosen, then for every polynomial time algorithm $A$ $$|Pr[A(g^a, g^b,g^{ab})=1] - Pr[A(g^a,g^b,g^c) = 1]|$$ is negligible.
\item Relating DL Assumptions:
\begin{itemize}
\item [$\circ$] Computing discrete logarithms is at least as hard as computing a Diffie-Hellman element $g^{ab}$ from $g^a$ and $g^b$.
\item [$\circ$] Computing a Diffie-Hellman element $g^ab$ from $g^a$ and $g^b$ is at least as hard as distinguishing a Diffie-Hellman triple $(g^a,g^b,g^{ab})$ from a random triple $(g^a,g^b,g^c)$.
\item [$\circ$] In most groups where the DL assumption is conjectured, DH and DDH assumptions are conjectured as well.
\item [$\circ$] There exists special elliptic curves where DDH problem is easy, but DH assumption is conjectured.
\end{itemize}
\end{itemize}

\subsection*{Security of El Gamal}

\begin{itemize}
\item Finding the secret key is equivalent to DL problem.
\item Finding the plaintext from the ciphertext and the public key is equivalent to DH problem.
\item The CPA security of El Gamal is equivalent to DDH problem.
\end{itemize}

\subsubsection*{Brute Force and Shank's}

\begin{itemize}
\item Let $G$ be a cyclic group of order $q$ and $g$ a generator. We wish to compute $\log_gy$.
\begin{itemize}
\item [$\circ$] Brute Force: $\mathcal{O}(q)$
\item [$\circ$] Shanks: Time and Space $\mathcal{O}(\sqrt{q})$.
\begin{itemize}
\item [$\circ$] Set $z = g^m$ (think of $m$ as $m = \sqrt{q}$).
\item [$\circ$] Compute $z^i$ for $0 \leq i \leq q/m$.
\item [$\circ$] Find $0 \leq j \leq m$ and $0 \leq i \leq q/m$ such that $yg^j = z^i$ and output $x = mi - j$.
\end{itemize}
\end{itemize}
\end{itemize}

\subsubsection*{Birthday Paradox}

\begin{itemize}
\item Lemma: Let $q_0, ..., q_k$ be randomly chosen in a set $S$. Then
\begin{itemize}
\item [$\circ$] the probability that $q_i = q_j$ for some $i \neq j$ is approximately $1-e^{-\frac{k^2}{2s}}$, where $s = |S|$, and
\item [$\circ$] with $k \approx \sqrt{-2s \ln (1 - \delta)}$ we have a collision-probability of $\delta$.
\end{itemize}
\item Proof: 
$$\bigg(\frac{s-1}{s}\bigg) \cdot \bigg(\frac{s-2}{s}\bigg) \cdot ... \cdot \bigg(\frac{s-k}{s}\bigg) \approx \prod_{i=1}^{k}e^{-\frac{i}{s}} \approx e^{-\frac{k^2}{2s}}$$
\end{itemize}

\subsubsection*{Pollard-$\rho$}

\begin{itemize}
\item Partition $G$ into $S_1, S_2,$ and $S_3$ "randomly".
\begin{itemize}
\item [$\circ$] Generate "random" sequence $\alpha_0, \alpha_1, \alpha_2...$
\begin{align*}
\alpha_0 &= g \\
\alpha_i &= 
\left\{
\begin{array}{ll}
\alpha_{i-1}g & \text{\ if \ } \alpha_{i-1} \in S_1\\
\alpha_{i-1}^2 & \text{\ if \ } \alpha_{i-1} \in S_2\\
\alpha_{i-1}y & \text{\ if \ } \alpha_{i-1} \in S_3\\
\end{array}
\right.
\end{align*}
\item [$\circ$] Each $\alpha_i = g^{a_i}y^{b_i}$, where $a_i, b_i \in \mathbb{Z}_q$ are known!
\item [$\circ$] If $\alpha_i = \alpha_j$ and $(a_i,b_i) \neq (a_j,b_j)$ then $y = g^{(a_i-a_j)(b_j-b_i)^{-1}}$.
\item [$\circ$] If $\alpha_i = \alpha_j$, then $\alpha_{i+1} = \alpha_{j+1}$.
\item [$\circ$] The sequence $(a_0,b_0),(a_1,b_1), ...$ is "essentially random".
\item [$\circ$] The Birthday bound implies that the (heuristic) expected running time is $\mathcal{O}(\sqrt{q})$.
\item [$\circ$] We use "double runners" to reduce memory.
\end{itemize}
\end{itemize}

\subsection*{Index Calculus}

\begin{itemize}
\item Let $\mathcal{B} = \{p_1, ..., p_B\}$ be a set of small prime integers.
\item Compute $a_i = \log_g p_i$ for all $p_i \in \mathcal{B}$.
\begin{itemize}
\item [$\circ$] Choose $s_j \in \mathbb{Z}_q$ randomly and attempt to factor $g^{s_j} = \prod_i p_i^{e_{j,i}}$ as an integer.
\item [$\circ$] If $g^{s_j}$ factored in $\mathcal{B}$ and $e_j = (e_{j,1}, ..., e_{j,B}$) is linearly independent of $e_i, ..., e_{j-1}$, then $j \gets j + 1$.
\item [$\circ$] If $j < B$, then go to (1).
\end{itemize}

\item Let $\mathcal{B} = \{p_1, ..., p_B\}$ be a set of small prime integers.
\item Compute $a_i = \log_g p_i$ for all $p_i \in \mathcal{B}$.
\begin{itemize}
\item [$\circ$] Choose $s \in \mathbb{Z}_q$ randomly.
\item [$\circ$] Attempt to factor $yg^s = \prod_i p_i^{e_i}$ as an integer.
\item [$\circ$] If a factorisation is found, then output $(\sum_i a_ie_i-s) \mod q$. 
\end{itemize}
\item Why doesn't this work for any cyclic group?
\end{itemize}

\subsubsection*{Example Groups}

\begin{itemize}
\item $\mathbb{Z}_n$ additively? Bad for crypto!
\item Large prime order subgroup of $\mathbb{Z}_p^*$ with $p$ prime. In particulate $p = 2q+1$ with $q$ prime.
\item Large prime order subgroup of $GF_{p^k}^*$.
\item "Carefully chosen" elliptic curve group.
\end{itemize}

\section*{Lecture 12 - Elliptic Curves \& Signature Schemes}

\begin{itemize}
\item We have argued that discrete logarithm problems are hard in large subgroups of $\mathbb{Z}_p^*$ and $\mathbb{F}_q^*$.
\item Based on discrete logarithm problems (DL, DH, DDH) we can construct public key cryptosystems, key exchange protocols, and signature schemes.
\item An elliptic curve is another candidate of a group where discrete logarithm problems are hard. 
\item Motivation for studying elliptic curves:
\begin{itemize}
\item [$\circ$] What if it turns out that solving discrete logarithms in $\mathbb{Z}_p^*$ is easy? Elliptic curves give an alternative.
\item [$\circ$] The best known DL-algorithms in an elliptic curve group with prime order $q$ are generic algorithms, i.e. the have running time $\mathcal{O}(\sqrt{q})$.
\item [$\circ$] Arguably we can use shorter keys. This is very important in some practical applications. 
\end{itemize}
\item Definition: A plane cubic curve $E$ (in Weierstrass form) over a field $\mathbb{F}$ is given by a polynomial $$y^2 = x^3 + ax + b$$ with $a,b \in \mathbb{F}$. The set of points $(x,y)$ that satisfy this equation $\mathbb{F}$ is written $E(\mathbb{F})$.
\item Every plane cubic curve over a field of characteristic $\neq 2,3$ can be written in the above form without changing any properties we care about.
\item We also write
\begin{align*}
g(x,y) &= x^3 + ax + b - y^2 \text{\ or \ } \\
y^2 &= f(x)
\end{align*}
where $f(x) = x^3 + ax + b$.
\end{itemize}

\subsection*{Singular Points}

\begin{itemize}
\item Definition: A point $(u,v) \in E(\mathbb{E})$, with $\mathbb{E}$ an extension field of $\mathbb{F}$, is singular if $$\frac{\partial g(x,y)}{\partial x}(u,v) = \frac{\partial g(x,y)}{\partial y}(u,v) = 0.$$
\item Definition: A plane cubic curve is smooth if $E(\overline{\mathbb{F}})$ contains no singular points.\\($\overline{\mathbb{F}}$ is the algebraic closure of $\mathbb{F}$.)
\item Note that
\begin{align*}
\frac{\partial g(x,y)}{\partial x}(x,y) &= f'(x) = 3x^2 + a \text{\ and \ }\\
\frac{\partial g(x,y)}{\partial y}(x,y) &= -2y
\end{align*}
\item Thus, any singular point $(u,v) \in E(\mathbb{F})$ must have:
\begin{itemize}
\item [$\circ$] $v=0$,
\item [$\circ$] $f(u) = 0$, and $f'(u) = 0$.
\end{itemize}
\item Then $f(x) = (x-u)h(x)$ and $f'(x) = h(x) + (x-u)h'(x)$, so $(u,v)$ is singular if $v=0$ and $u$ is a double-root of $f$.
\end{itemize}

\subsection*{Discriminant}

\begin{itemize}
\item In general a "discriminant" can be used to check if a polynomial has a double root.
\item Definition: The discriminant $\Delta(E)$ of a plane curve $y^2 = x^3 + ax + b$ is given by $-4a^3 - 27b^2$.
\item Lemma: The polynomial $f(x)$ does not have a double root iff $\Delta(E) \neq 0$, in which case the curve is called smooth.
\end{itemize}

\subsection*{Line Defined By Two Points On Curve}

\begin{itemize}
\item Let $l(x)$ be a line that intersects the curve in $(u_1,v_1)$ and $(u_2,v_2)$. Then $$l(x) = k(x-u_1) + v_1$$ where 
$$k = 
\left\{
\begin{array}{ll}
\frac{v_2-v_1}{u_2-u_1} & \text{\ if \ } (u_1,v_1) \neq (u_2,v_2)\\
\frac{3u_1^2 + a}{2v_1} & \text{\ otherwise \ }
\end{array}
\right.$$
\item We are cheating a little here in that we assume that we don't have $u_1 = u_2$ and $v_1 \neq v_2$ or $v_1 = v_2 = 0$. In both such cases we get a line parallel with $x = 0$ that we deal with in a special way.
\end{itemize}

\subsection*{Finding the Third Point}

\begin{itemize}
\item The intersection points between $l(x)$ and the curve are given by the zeros of $$t(x) = g(l(x),x) = f(x) - l(x)^2$$ which is a cubic polynomial with known roots $u_1$ and $u_2$.
\item To find the third intersection point $(u_3,v_3)$ we note that $$t(x) = (x-u_1)(x-u_2)(x-u_3) = x^3 - (u_1 + u_2 + u_3)x^2 + r(x)$$ where $r(x)$ is linear. Thus, we can find $u_3$ from $t$'s coefficients!
\item Given any two points $A$ and $B$ on the curve that defines a line, we can find a third intersection point $C$ with the curve (even if $A = B$).
\item The only exception is if our line $l(x)$ is parallel with the $y$-axis.
\item To "fix" this exception we add a point at infinity $O$, roughly at $(0,\infty)$ (the projective plane). Intuition: the side of a long straight road seem to intersect infinitely far away.
\item We define the sum of $A$ and $B$ by $(x, -y)$, where $(x,y)$ is the third intersection point of the line defined by $A$ and $B$  with the curve.
\item We define the inverse of $(x,y)$ by $(x,-y)$.
\item The main technical difficulty in proving that this gives a group is to prove the associative law. This can be done with Bezout's theorem (not the one covered in class), or by (tedious) elementary algebraic manipulation.
\end{itemize}

\subsection*{Elliptic Curves}

\begin{itemize}
\item There are many elliptic curves with special properties. 
\item There are many ways to represent the same curve and to implement curves as well as representing and implementing the underlying field.
\item More requirements than smoothness must be satisfied for a curve to be suitable for cryptographic use.
\item Fortunately, there are standardised curves.\\(I would need a very strong reason not to use these curves and I would be extremely careful, consulting researchers specialising in elliptic curve cryptography.)
\end{itemize}

\subsection*{Signature Schemes}

\subsubsection*{Digital Signature}

\begin{itemize}
\item A digital signature is the public-key equivalent of a MAC; the receiver verifies the integrity and authenticity of a message.
\item Does a digital signature replace a real handwritten one?
\end{itemize}

\subsubsection*{Textbook RSA Signature}

\begin{itemize}
\item Generate RSA keys $((N,e), (p,q,d))$.
\item To sign a message $m \in \mathbb{Z}_N$, compute $\sigma = m^d \mod N$.
\item To verify a signature $\sigma$ of a message $m$ verify that $\sigma^e = m \mod N$.
\item Are Textbook RSA Signatures any good?
\item If $\sigma$ is a signature of $m$, then $\sigma^2 \mod N$ is a signature of $m^2 \mod N$.
\item If $\sigma_1$ and $\sigma_2$ are signatures of $m_1$ and $m_2$, then $\sigma_1\sigma_2 \mod N$ is a signature of $m_1m_2 \mod N$.
\item We can also pick a signature $\sigma$ and compute the message it is a signature of by $m = \sigma^e \mod N$.
\item We must be more careful!
\end{itemize}

\subsubsection*{Signature Scheme}

\begin{itemize}
\item Gen generates a key pair (pk, sk).
\item Sig takes a secret key sk and a message $m$ and computes signature $\sigma$.
\item Vf takes a public key pk, a message $m$, and a candidate signature $\sigma$, verifies the candidate signature, and outputs a single-bit verdict.
\end{itemize}

\subsubsection*{Existential Unforgeability}

\begin{itemize}
\item Definition: A signature scheme (Gen, Sig, Vf) is secure against existential forgeries if for every polynomial time algorithm $A$ and a random key pair (pk, sk) $\gets$ Gen($1^n$),
$$Pr[A^{\text{Sig}_{\text{sk}}(\cdot)}(\text{pk}) = (m, \sigma) \land \text{Vf}_{\text{pk}}(m,\sigma) = 1 \land\ \forall i : m \neq m_i]$$
is negligible where $m_i$ is the $i$\ts{th} query to $\text{Sig}_{\text{sk}}(\cdot)$.
\end{itemize}

\subsubsection*{Provably Secure Signature Schemes}

\begin{itemize}
\item Provably secure signature schemes exist if one-way functions exist (in plain model without ROM), but the construction is more involved and typically less efficient.
\item Provably secure signature schemes are rarely used in practice!
\item Standards used in practices: RSA Full Domain Hash, DSA, EC-DSA. The latter two may be viewed as variants of Schnorr signatures.
\end{itemize}

\section*{Lecture 13 - Trapdoor One-Way Permutations \& PKIs}

\subsection*{Based on Trapdoor One-Way Permutations}

\begin{itemize}
\item Let $f = \{f_\alpha\}$ be an ensemble of permutations (bijections).
\begin{itemize}
\item [$\circ$] Gen generates a random key pair $\alpha$ = (pk, sk). Less formaly Gen generates a pair $(f_\alpha,f_\alpha^{-1})$.
\item [$\circ$] Eval takes pk and $x$ as input and efficiently evaluates $f_\alpha(x)$.
\item [$\circ$] Invert takes sk and $y$ as input and efficiently evaluates the inverse $f_\alpha^{-1}(y)$.
\end{itemize}
\item One-way if Eval$_\text{pk}(\cdot)$ is one-way for a random pk.
\item RSA is a trap-door permutation over $\mathbb{Z}_N^*$.
\end{itemize}

\subsubsection*{Full Domain Hash Signature in ROM}

\begin{itemize}
\item Let $f = \{f_\alpha\}$ be a trapdoor permutation (family) and let $H: \{0,1\}^* \rightarrow \{0,1\}^n$ be a random oracle.
\begin{itemize}
\item [$\circ$] Gen samples a pair $(f_\alpha,f_\alpha^{-1})$.
\item [$\circ$] Sig takes $f_\alpha^{-1}$ and a message $m$ as input and outputs $f_\alpha^{-1}\big(H(m)\big)$.
\item [$\circ$] Vf takes $f_\alpha$, a message $m$, and a candidate signature $\sigma$ as input, and outputs 1 if $f_\alpha(\sigma) = H(m)$ and 0 otherwise.
\end{itemize}
\end{itemize}

\subsection*{Based on Proofs of Knowledge}

\subsubsection*{Proof of Knowledge of Exponent}

\begin{itemize}
\item In an identification scheme one party convinces another that it holds some special token.
\begin{itemize}
\item [$\circ$] Let $G_q$ be a group of prime order $q$ with generator $g$.
\item [$\circ$] Let $x \in \mathbb{Z}_q$ and define $y = g^x$.
\item [$\circ$] Can we prove knowledge of $x$ without disclosing anything about $x$?
\end{itemize}
\end{itemize}

\subsubsection*{Schnorr's Protocol}

\begin{itemize}
\item The prover chooses $r \in \mathbb{Z}_q$ randomly and hands $\alpha = g^r$ to the verifier.
\item The verifier chooses $c \in \mathbb{Z}_q$ randomly and hands it to the prover.
\item The prover computes $d = cx + r \mod q$ and hands $d$ to the verifier.
\item The verifier accepts if $y^c\alpha = g^d$.
\item Suppose that a machine convinces us in the protocol with probability $\delta$. Does it mean that is knows $x$ such that $y = g^x$?
\item Run the machine to get $\alpha$.
\item Complete the interaction twice using the same $\alpha$, once for a challenge $c$ and once for a challenge $c'$, where $c,c' \in \mathbb{Z}_q$ are chosen randomly.
\item Repeat the previous two steps until the resulting interactions $(\alpha, c, d)$ and $(\alpha, c', d')$ are accepting and $c \neq c'$.
\item Note that:
$$y^{c-c'} = \frac{y^c}{y^{c'}} = \frac{y^c\alpha}{y^{c'}\alpha} = \frac{g^d}{g^{d'}} = g^{d-d'}$$ which gives the logarithm $x = (d-d')(c-c')^{-1} \mod q$ such that $y = g^x$.
\item Anybody can sample $c,d \in \mathbb{Z}_q$ randomly and compute $\alpha = g^d / y^c$.
\item The resulting tuple $(\alpha, c, d)$ has exactly the same distribution as the transcript of an interaction!
\item Such protocols are called (honest verifier) zero-knowledge proofs of knowledge.
\end{itemize}

\subsubsection*{Schnorr's Signature Scheme in ROM}

\begin{itemize}
\item Let $H: \{0,1\}^* \rightarrow \mathbb{Z}_q$ be a random oracle.
\begin{itemize}
\item [$\circ$] Gen chooses $x \in \mathbb{Z}_q$ randomly, computes $y = g^x$ and outputs (pk, sk) = $(y,x)$.
\item [$\circ$] Sig does the following on input $x$ and $m$:
\begin{enumerate}
\item it chooses $r \in \mathbb{Z}_q$ randomly and computes $\alpha = g^r$,
\item it computes $c = H(y, \alpha, m),$
\item it computes $d = cx + r \mod q$ and outputs $(\alpha, d)$.
\end{enumerate}
\item [$\circ$] Vf takes the public key $y$, a message $m$ and a candidate signature $(\alpha, d)$, and accepts iff $y^{H(y,\alpha, m)}\alpha = g^d$.
\end{itemize}
\end{itemize}

\subsubsection*{PKIs}

\begin{itemize}
\item We have constructed public-key crypotsystems and signature schemes.
\item Only the holder of the secret key can decrypt ciphertexts and sign messages.
\item How do we know who holds the secret key corresponding to a public key?
\end{itemize}

\subsubsection*{Signing Public Keys of Others}

\begin{itemize}
\item Suppose that Alice computes a signature $\sigma_{A,B} = $ Sig$_{\text{sk}_A}$ (pk$_B, Bob$) of bob's public key pk$_B$ and his identity and hands it to Bob.
\item Suppose that Eve holds Alice's public key pk$_A$.
\item Then anybody can hand (pk$_B$, $\sigma_{A,B}$) directly to Eve, and Eve will be convinced that pk$_B$ is Bob's key (assuming she trusts Alice).
\end{itemize}

\subsubsection*{Certificate}

\begin{itemize}
\item A certificate is a signature of a public key along with some information on how the key may be used, e.g., it may allow the holder to issue certificates.
\item A certificate is valid for a given setting if the signature is valid and the usage information in the certificate matches that of the setting.
\item Some parties mus be trusted to issue certificates. These parties are called Certificate Authorities (CA).
\end{itemize}

\subsubsection*{Certificate Chains}

\begin{itemize}
\item A CA may be "distribute" using in certificate chains.
\begin{itemize}
\item [$\circ$] Suppose that Bob holds valid certificates $$\sigma_{0,1}, \sigma_{1,2}, ...,  \sigma_{n-1,n}$$ where $\sigma_{i-1,i}$ is a certificate of pk$_{P_i}$ by $P_{i-1}$.
\item [$\circ$] Who does Bob trust?
\end{itemize}
\end{itemize}

\subsection*{Pseudo-random Generators}

\begin{itemize}
\item Everything we have done so far requires randomness!
\item Can we "generate" random strings?
\item We could flip actual coins. This would be extremely impractical and slow (and boring unless you are Rain man).
\item We could generate "physical" randomness using hardware, e.g., measuring radioactive decay
\begin{itemize}
\item [$\circ$] Slow or expensive.
\item [$\circ$] Hard to verify and trust.
\item [$\circ$] Biased output.
\end{itemize}
\item We could use a deterministic algorithm that outputs a "random looking string", but would that be secure?
\end{itemize}

\subsubsection*{Pseudo-Random Generator}

\begin{itemize}
\item A pseudo-random generator requires a short random string and deterministically expands this to a longer "random looking" string. 
\item This looks promising:
\begin{itemize}
\item [$\circ$] Fast and cheap?
\item [$\circ$] Practical since it can be implemented in software or hardware?
\item [$\circ$] What is "random looking"?
\end{itemize}
\end{itemize}

\section*{Lecture 14 - Pseudo-Random Generator}

\begin{itemize}
\item Definition: An efficient algorithm PRG is a pseudo-random generator (PRG) if there exists a polynomial $p(n) > n$ such that for every polynomial time adversary $A$, if a seed $S \in \{0,1\}^n$ and a random string $u \in \{0,1\}^{p(n)}$ are chosen randomly, then $$|Pr[A(\text{PRG}(s)) =1] - Pr[A(u) = 1]|$$ is negligible. 
\item informally, $A$ can not distinguish PRG($s$) from a truly random string in $\{0,1\}^{p(n)}$.
\item Before we consider how to construct a PRG we consider what the definition gives us:
\begin{itemize}
\item [$\circ$] Suppose that there exists a PRG that extends its output by a single bit.
\item [$\circ$] This would not be very useful to us, e.g., to generate a random prime we need many random bits.
\item [$\circ$] Can we use the given PRG to construct another PRG which extends its output more?
\end{itemize}
\item Construction: Let PRG be a pseudo-random generator. We let PRG$_t$ be the algorithm that takes $s_{-1} \in \{0,1\}^n$ as input, computes $s_0, ..., s_{t-1}$ and $b_0,...,b{t-1}$ as $$(s_i,b_i)= \text{PRG}(s_{i-1})$$ and outputs $(b_0,...,b{t-1}$.
\item Theorem: Let $p(n)$ be a polynomial and PRG a pseudo-random generator. Then PRG$_{p(n)}$ is a pseudo-random generator that on input $s \in \{0,1\}^n$ outputs a string in $\{0,1\}^{p(n)}$.
\item We can go on "forever"!
\end{itemize}

\subsubsection*{Random String From Random Oracle}

\begin{itemize}
\item Theorem: If $F: \{0,1\}^n \rightarrow \{0,1\}^m$ is a random function, then $(F(0),F(1),F(2),...,F(t-1))$ is a $tm$-bit string.
\item Can we do this using a pseudo-random function?
\item Can we replace the random function by SHA-2?
\end{itemize}

\subsubsection*{Pseudo-Random Function}

\begin{itemize}
\item Recall the definition of a pseudo-random function.
\item Definition: A family of functions $F: \{0,1\}^k \times \{0,1\}^n \rightarrow \{0,1\}^n$ is pseudo-random if for all polynomial time oracle adversaries $A$
$$\Bigg|\Pr_{K} \Big[A^{F_K(\cdot)}=1 \Big] - \Pr_{R:\{0,1\}^n\rightarrow\{0,1\}^n} \Big[A^{R(\cdot)}=1\Big] \Bigg|$$ is negligible.
\end{itemize}

\subsubsection*{Pseudo-Random Generator From Pseudo-Random Function}

\begin{itemize}
\item Theorem: Let $\{F_K\}_{K \in \{0,1\}^k}$ be a pseudo-random function for a random choice of $K$. then the PRG defined by:
$$\text{PRG}(s) = (F_s(0),F_s(1),F_s(2),...,F_s(t))$$ is a pseudo-random generator.
\item Construction: Let PRG: $\{0,1\}^k \rightarrow \{0,1\}^{2k}$ be a pseudo-random generator, and define a family of functions $F = \{F_K\}_{K \in \{0,1\}^k}$ as follows.
\begin{itemize}
\item [$\circ$] Let $x_{[i]} = (x_0,...,x_i)$
\item [$\circ$] On key $K$ and input $x, F_K$ computes its output as follows:
\begin{enumerate}
\item computes $(r_0^0,r_1^0) = \text{PRG}(K)$.
\item Computes $$(r^i_{x_{[i-1]}||0},r^i_{x_{[i-1]}||1}) = \text{PRG}(r^{i-1}_{x_{[i-1]}})$$ for $i = 1,...,n-1$.
\item Outputs $r_{x_{[n-1]}}$.
\end{enumerate}
\end{itemize}
\end{itemize}

\subsubsection*{One-Way Permutation}

\begin{itemize}
\item Definition: A family $F = \{f_n\}$ of permutations $f_n \{0,1\}^n \rightarrow \{0,1\}^n$ is said to be one-way if for a random $x \in \{0,1\}^n$ and every polynomial time algorithm $A$ $$Pr[A(f_n(x)) = x] < \epsilon(n)$$ for a negligible function $\epsilon(n)$.
\item (Note that for permutations we may request the unique preimage.)
\end{itemize}

\subsubsection*{Hardcore Bit}

\begin{itemize}
\item Definition: Let $F = \{f_n\}$ be a family of permutations $f_n : \{0,1\}^n \rightarrow \{0,1\}^n$ and $B = \{b_n\}$ a family of "bits" $b_n : \{0,1,\}^n \rightarrow \{0,1\}$. Then $B$ is a hardcore bit of $F$ if for random $x \in \{0,1\}^n$ and every polynomial time algorithm $A$ $$|Pr[A(f_n(x)) = b_n(x)] - 1/2| < \epsilon(n)$$ for a negligible function $\epsilon(n)$.
\item Theorem: For every one-way permutation, there is a (possibly different) one-way permutation with a hardcore bit.
\end{itemize}

\subsubsection*{PRG from One-Way Permutation}

\begin{itemize}
\item Construction: Let $F$ be a one-way permutation and define PRG by PRG$_n(s) = f_n(s)||b_n(s)$ for $x \in \{0,1\}^n$.
\item Theorem: PRG : $\{0,1\}^n \rightarrow \{0,1\}^{n+1}$ is a pseudo-random generator.
\end{itemize}

\subsubsection*{PRG From Any One-Way Function}

\begin{itemize}
\item Theorem: There is a construction PRG$_f$ that is a a PRG if $f$ is a one-way function (possibly non-permutation).
\item The construction is very involved and is completely impractical. (Johan H\aa stad)
\end{itemize}

\subsubsection*{What is Used in Practice?}

\begin{itemize}
\item Various standards contain some of the following elements.
\begin{itemize}
\item [$\circ$] Fast hardware generator + "algorithmic strengthening".
\item [$\circ$] \texttt{/dev/random}
\begin{itemize}
\item Entropy gathering deamon with estimate of amount of entropy.
\item FreeBSD: Executes the PRG \textit{Yarrow} (or \textit{Futura}) pseudo-random algorithm.
\item SunOs and Un*xes use similar approaches.
\item Windows has similar devices.
\end{itemize}
\item [$\circ$] Stream cipher, e.g. block-cipher in CFB or CTR mode.
\item [$\circ$] Hashfunction with secret prefix and counter (essentially our PRF $\rightarrow$ PRG construction).
\end{itemize}
\end{itemize}

\subsubsection*{Infamous Mistakes}

\begin{itemize}
\item (1995) The original Netscape SSL code used time of the day and process IDs to seed its pseudo random giving way too little entropy in the seed. 
\item (2008) Debian's OpenSSL commented out a critical part of the code that reduced the entropy of keys drastically!
\item (2012) RSA public keys with common factors.
\end{itemize}

\subsubsection*{Important Conclusions}

\begin{itemize}
\item Security bugs are not found by testing!
\item With an insecure pseudo-random generator anything on top of it will be insecure.
\item Any critical code must be reviewed after every modification, e.g., keep hashes of critical code.
\end{itemize}

\end{document}